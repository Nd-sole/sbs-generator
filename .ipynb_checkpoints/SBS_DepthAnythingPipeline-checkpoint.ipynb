{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cee2917f",
   "metadata": {},
   "source": [
    "\n",
    "# SBS 3D Video Generation Pipeline\n",
    "\n",
    "This notebook outlines the process of converting a monocular video into a side-by-side (SBS) 3D video.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e231e45a",
   "metadata": {},
   "source": [
    "\n",
    "## Setup and Preparation\n",
    "\n",
    "Import necessary libraries and define the input video path.\n",
    "\n",
    "Personally, I opt for the file structure `datasets/d{index}/[set of input/output folder for frames]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca7e718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "dataset = 0\n",
    "# Define the path to the input video\n",
    "dataset_directory = f'datasets/d{dataset}/'\n",
    "input_video_path = dataset_directory + 'test.mp4'\n",
    "final_video_filename = dataset_directory + 'test_SBS.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f38ce7a-0b99-41dc-b262-bd537bbe2306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stable way of tracking accurate pixel shift records\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_disparity(depth_value, scale_factor):\n",
    "    try:\n",
    "        disparity = int(depth_value * scale_factor)\n",
    "        return disparity\n",
    "    except Exception as e:\n",
    "        print(f\"Exception in calculate_disparity for depth_value {depth_value}: {e}\")\n",
    "        return 0\n",
    "\n",
    "def shift_pixels(image, depth_map, direction, scale_factor, shift_threshold, frame_name, output_dir):\n",
    "    try:\n",
    "        print(\"Starting shift_pixels operation with handling for black pixels and significant shifts\")\n",
    "\n",
    "        # Calculate disparity map and apply scaling factor\n",
    "        disparity_map = (depth_map.astype(np.float32) * scale_factor).astype(np.int32)\n",
    "\n",
    "        # Get image dimensions\n",
    "        height, width = image.shape[:2]\n",
    "\n",
    "        # Initialize shifted image with zeros (black)\n",
    "        shifted_image = np.zeros_like(image)\n",
    "\n",
    "        # List to store indexes of pixels that are shifted significantly\n",
    "        significant_shift_indexes = []\n",
    "\n",
    "        for y in range(height):\n",
    "            for x in range(width):\n",
    "                disparity = disparity_map[y, x]\n",
    "                new_x = x + disparity * direction\n",
    "                \n",
    "                # Check if new_x is within bounds\n",
    "                if 0 <= new_x < width:\n",
    "                    shifted_image[y, new_x] = image[y, x]\n",
    "                    # If the shift is significant, add it to the list\n",
    "                    if abs(disparity) >= shift_threshold:\n",
    "                        linear_index = y * width + new_x  # Use new_x as the shift has occurred\n",
    "                        significant_shift_indexes.append(linear_index)\n",
    "                else:\n",
    "                    # Out of bounds shifts are also significant by default\n",
    "                    linear_index = y * width + x\n",
    "                    significant_shift_indexes.append(linear_index)\n",
    "\n",
    "        # Save the significant shift indexes to a .txt file\n",
    "        significant_shifts_filename = f\"{frame_name}_significant_shifts.txt\"\n",
    "        significant_shifts_filepath = os.path.join(output_dir, significant_shifts_filename)\n",
    "        \n",
    "        with open(significant_shifts_filepath, 'w') as file:\n",
    "            for index in significant_shift_indexes:\n",
    "                file.write(f\"{index}\\n\")\n",
    "\n",
    "        print(f\"Significant shift indexes saved to {significant_shifts_filepath}\")\n",
    "\n",
    "        return shifted_image\n",
    "    except Exception as e:\n",
    "        print(f\"Exception in shift_pixels: {e}\")\n",
    "        return np.zeros_like(image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_image_pair(color_image_path, depth_image_path, output_dir, frame_number, scale_factor):\n",
    "    try:\n",
    "        print(f\"Thread started for frame {frame_number}\")\n",
    "\n",
    "        color_image = cv2.imread(color_image_path)\n",
    "        depth_map = cv2.imread(depth_image_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "        if color_image is None or depth_map is None:\n",
    "            print(f\"Error: Missing image for frame {frame_number}\")\n",
    "            return\n",
    "\n",
    "        # Assuming depth_map might not be in grayscale, convert if necessary\n",
    "        if depth_map.ndim == 3:\n",
    "            depth_map = cv2.cvtColor(depth_map, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # left_eye_image = shift_pixels(color_image, depth_map, 1, scale_factor)\n",
    "        frame_name = os.path.splitext(os.path.basename(color_image_path))[0]\n",
    "        left_eye_image = shift_pixels(color_image, depth_map, 1, scale_factor, 1, frame_name, output_dir)\n",
    "        right_eye_image = shift_pixels(color_image, depth_map, -1, scale_factor, 1, frame_name, output_dir)\n",
    "\n",
    "        if not os.path.exists(os.path.join(output_dir,'leftEye')):\n",
    "            os.makedirs(os.path.join(output_dir,'leftEye'))\n",
    "        if not os.path.exists(os.path.join(output_dir,'rightEye')):\n",
    "            os.makedirs(os.path.join(output_dir,'rightEye'))\n",
    "        \n",
    "        left_eye_output_path = os.path.join(output_dir, f'leftEye/leftEye{frame_number}.jpg')\n",
    "        right_eye_output_path = os.path.join(output_dir, f'rightEye/rightEye{frame_number}.jpg')\n",
    "\n",
    "        # Save the left and right eye images\n",
    "        cv2.imwrite(left_eye_output_path, left_eye_image)\n",
    "        cv2.imwrite(right_eye_output_path, right_eye_image)\n",
    "\n",
    "        print(f\"Processed and saved images for frame {frame_number}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception in process_image_pair for frame {frame_number}: {e}\")\n",
    "\n",
    "\n",
    "# Setup directories and process images\n",
    "input_directory = \"C:/Users/abahrema/Documents/Tools/sbs-generator/datasets/d0/rgbd_in\"\n",
    "output_directory = \"C:/Users/abahrema/Documents/Tools/sbs-generator/datasets/d0/scratch_test_savedShifts\"\n",
    "print(\"Creating output directory if it doesn't exist.\")\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "print(\"Reading color images from the input directory.\")\n",
    "\n",
    "color_images = sorted([f for f in os.listdir(input_directory) if f.startswith('color')])\n",
    "depth_images = sorted([f for f in os.listdir(input_directory) if f.startswith('depth')])\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=os.cpu_count() - 1) as executor:\n",
    "    futures = []\n",
    "    for color_image, depth_image in zip(color_images, depth_images):\n",
    "        color_image_path = os.path.join(input_directory, color_image)\n",
    "        depth_image_path = os.path.join(input_directory, depth_image)\n",
    "        frame_number = color_image.split('color')[1].split('.')[0]\n",
    "        futures.append(executor.submit(process_image_pair, color_image_path, depth_image_path, output_directory, frame_number, 0.1))\n",
    "\n",
    "    # Progress tracking\n",
    "    for f in tqdm(concurrent.futures.as_completed(futures), total=len(futures)):\n",
    "        pass\n",
    "\n",
    "print(\"Image processing completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10130fcc",
   "metadata": {},
   "source": [
    "## Import and Setup Depth Anything Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4411cb24",
   "metadata": {},
   "source": [
    "Run depth anything model for video input, specify if wishing to include depth model locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7209e034",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = False\n",
    "local_path_directory = \"your_local_directory\"\n",
    "current_working_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226bd37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if local_path:\n",
    "    local_path_directory = r\"depth_models\"\n",
    "    # Clone the repository\n",
    "    os.system(\"git clone https://github.com/LiheYoung/Depth-Anything\")\n",
    "    # Change directory to the cloned repository\n",
    "    os.chdir(\"Depth-Anything\")\n",
    "    # Create a Conda environment named 'depth-anything' with Python 3.11\n",
    "    os.system(\"conda create -n depth-anything python=3.11\")\n",
    "    # Activate the Conda environment\n",
    "    os.system(\"conda activate depth-anything\")\n",
    "    # Install PyTorch and other dependencies\n",
    "    os.system(\"conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia\")\n",
    "    # Install additional Python packages from requirements.txt\n",
    "    os.system(\"pip install -r requirements.txt\")\n",
    "    # Print a message to indicate successful setup\n",
    "    print(\"Project setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feb59fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not local path, specify remote path for depth-anything\n",
    "remote_path = r\"..\\Depth-Anything\"\n",
    "if not local_path: local_path_directory = remote_path\n",
    "print(f\"Path set {local_path_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbc0f49-637c-44f0-89e3-4ae5edce2a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkPath(path):\n",
    "    if os.path.exists(path): print(f\"The file '{path}' exists.\")\n",
    "    else: print(f\"The file '{path}' does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0cd115",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbd_frames = dataset_directory + 'rgbd_in/'\n",
    "os.makedirs(rgbd_frames, exist_ok=True)\n",
    "\n",
    "print(f\"dataset directory {dataset_directory}\\n video dire {input_video_path}\\n outdir {dataset_directory}\")\n",
    "print(f\"local path {local_path_directory}\")\n",
    "\n",
    "# Check if the file exists\n",
    "file_path = os.path.join(local_path_directory, \"run_depth_only.py\")\n",
    "\n",
    "# Get the current working directory\n",
    "current_working_directory = os.getcwd()\n",
    "\n",
    "# Define the full paths to input video and dataset directory\n",
    "input_video_path_full = os.path.join(current_working_directory, input_video_path)\n",
    "dataset_directory_full = os.path.join(current_working_directory, dataset_directory)\n",
    "checkPath(input_video_path_full)\n",
    "checkPath(dataset_directory_full)\n",
    "\n",
    "\n",
    "os.chdir(local_path_directory)\n",
    "!python {local_path_directory}/run_depth_only.py --encoder vitl --video-path {input_video_path_full} --outdir {dataset_directory_full}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caf08b7",
   "metadata": {},
   "source": [
    "\n",
    "## Extract Frames from Video\n",
    "\n",
    "Use ffmpeg to extract frames from the input color video and depth video.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f411238e-ce3f-4fb8-8082-9a135ce9c4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch directory back\n",
    "output_depth_video = dataset_directory + \"test_video_depth.mp4\"\n",
    "os.chdir(current_working_directory)\n",
    "print(f\"Changed directory to {current_working_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d488a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create directory if non-existent\n",
    "output_frames_path = dataset_directory + 'rgbd_in/frame%d.jpg'\n",
    "output_dir = os.path.dirname(output_frames_path)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"output_frames_path: {output_frames_path}, output_dir: {output_dir}\")\n",
    "print(f\"video {input_video_path}\")\n",
    "# execute ffmpeg command for color\n",
    "!ffmpeg -i {input_video_path} -q:v 2 {output_frames_path} \n",
    "output_frames_path = dataset_directory + 'rgbd_in/frame%d.png' # for depth\n",
    "!ffmpeg -i {output_depth_video} -q:v 2 {output_frames_path}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb9eaab",
   "metadata": {},
   "source": [
    "\n",
    "## Image Preprocessing\n",
    "\n",
    "Rename and pair color and depth images as needed. Run the script or run the function inside notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d702eabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbd_frames = dataset_directory + 'rgbd_in/'\n",
    "# Example for renaming images (adjust according to your script)\n",
    "!python sbs_rename_directory.py {rgbd_frames}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5f706d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def get_frame_number(filename):\n",
    "    match = re.search(r\"frame(\\d+)_\", filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid filename format: {filename}\")\n",
    "        \n",
    "def rename_files(source_dir):\n",
    "    os.makedirs(source_dir, exist_ok=True)\n",
    "\n",
    "    # Process color images\n",
    "    color_files = sorted([f for f in os.listdir(source_dir) if f.startswith(\"frame\") and f.endswith(\".jpg\")], \n",
    "                         key=lambda x: int(x.split(\"frame\")[1].split(\".\")[0]))\n",
    "    counter = 1\n",
    "    for filename in color_files:\n",
    "        new_name = f\"color{counter}.jpg\"\n",
    "        os.rename(os.path.join(source_dir, filename), os.path.join(source_dir, new_name))\n",
    "        counter += 1\n",
    "    print(f\"Renamed {counter} color files in {source_dir}.\")\n",
    "\n",
    "    # Process depth images\n",
    "    depth_files = sorted([f for f in os.listdir(source_dir) if f.startswith(\"frame\") and f.endswith(\".png\")], \n",
    "                         key=lambda x: int(x.split(\"frame\")[1].split(\".\")[0]))\n",
    "    counter = 1\n",
    "    for filename in depth_files:\n",
    "        new_name = f\"depth{counter}.png\"\n",
    "        os.rename(os.path.join(source_dir, filename), os.path.join(source_dir, new_name))\n",
    "        counter += 1\n",
    "    print(f\"Renamed {counter} depth files in {source_dir}.\")\n",
    "    \n",
    "source_dir = dataset_directory + \"rgbd_in/\"\n",
    "rename_files(source_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca376732",
   "metadata": {},
   "source": [
    "\n",
    "## Generate Stereo Views\n",
    "\n",
    "Run the script to generate left and right eye views or run the function inside notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d21ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stereo_input_dir =  dataset_directory + \"rgbd_in/\"\n",
    "stereo_output_dir = dataset_directory + \"stereo_out_frames/\"\n",
    "os.makedirs(stereo_input_dir, exist_ok=True)\n",
    "os.makedirs(stereo_output_dir, exist_ok=True)\n",
    "\n",
    "!python sbs_generate_stereoviews.py {stereo_input_dir} {stereo_output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd8b667-4e79-477b-907f-020df9d2957b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# stable\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_disparity(depth_value, scale_factor):\n",
    "    try:\n",
    "        disparity = int(depth_value * scale_factor)\n",
    "        return disparity\n",
    "    except Exception as e:\n",
    "        print(f\"Exception in calculate_disparity for depth_value {depth_value}: {e}\")\n",
    "        return 0\n",
    "\n",
    "def shift_pixels(image, depth_map, direction, scale_factor):\n",
    "    try:\n",
    "        print(\"Starting shift_pixels operation with handling for black pixels\")\n",
    "\n",
    "        # Calculate disparity map and apply scaling factor\n",
    "        disparity_map = (depth_map.astype(np.float32) * scale_factor).astype(np.int32)\n",
    "\n",
    "        # Get image dimensions\n",
    "        height, width, _ = image.shape\n",
    "\n",
    "        # Generate grid of x and y coordinates\n",
    "        x_grid, y_grid = np.meshgrid(np.arange(width), np.arange(height))\n",
    "\n",
    "        # Calculate new x coordinates after applying disparity shift\n",
    "        new_x = x_grid + (disparity_map * direction)\n",
    "\n",
    "        # Initialize shifted image with zeros (black)\n",
    "        shifted_image = np.zeros_like(image)\n",
    "\n",
    "        # Determine which of the new x coordinates are within image bounds\n",
    "        in_bounds_mask = (new_x >= 0) & (new_x < width)\n",
    "\n",
    "        # Use boolean indexing to select pixels within bounds and assign them to the new coordinates in the shifted image\n",
    "        shifted_image[y_grid[in_bounds_mask], new_x[in_bounds_mask]] = image[y_grid[in_bounds_mask], x_grid[in_bounds_mask]]\n",
    "\n",
    "        print(\"Completed shift_pixels operation with handling for black pixels\")\n",
    "        return shifted_image\n",
    "    except Exception as e:\n",
    "        print(f\"Exception in shift_pixels: {e}\")\n",
    "        return np.zeros_like(image)\n",
    "\n",
    "\n",
    "def fast_shift_pixels(image, depth_map, direction, scale_factor):\n",
    "    try:\n",
    "        print(\"Starting shift_pixels operation with disparity calculation\")\n",
    "\n",
    "        # Ensure depth_map is a 2D array if it's not already grayscale\n",
    "        if depth_map.ndim == 3:\n",
    "            depth_map = cv2.cvtColor(depth_map, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Calculate disparity as a 2D array\n",
    "        disparity = (depth_map.astype(np.float32) * scale_factor).astype(np.int32)\n",
    "\n",
    "        # Create an array of x-coordinates and add the disparity to shift\n",
    "        # Note: We're limiting the shift to ensure it remains within image bounds\n",
    "        x_coords = np.arange(image.shape[1])\n",
    "        y_coords = np.arange(image.shape[0])[:, None]  # Making it a column vector for broadcasting\n",
    "\n",
    "        # Calculate new x-coordinates after applying the disparity shift\n",
    "        # Using np.clip to ensure the shifted coordinates remain within bounds\n",
    "        shifted_x_coords = np.clip(x_coords + disparity * direction, 0, image.shape[1] - 1)\n",
    "\n",
    "        # Use advanced indexing to create the shifted image\n",
    "        shifted_image = image[y_coords, shifted_x_coords]\n",
    "\n",
    "        print(\"Completed shift_pixels operation with disparity calculation\")\n",
    "        return shifted_image\n",
    "    except Exception as e:\n",
    "        print(f\"Exception in shift_pixels: {e}\")\n",
    "        return np.zeros_like(image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_image_pair(color_image_path, depth_image_path, output_dir, frame_number, scale_factor):\n",
    "    try:\n",
    "        print(f\"Thread started for frame {frame_number}\")\n",
    "\n",
    "        color_image = cv2.imread(color_image_path)\n",
    "        depth_map = cv2.imread(depth_image_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "        if color_image is None or depth_map is None:\n",
    "            print(f\"Error: Missing image for frame {frame_number}\")\n",
    "            return\n",
    "\n",
    "        # Assuming depth_map might not be in grayscale, convert if necessary\n",
    "        if depth_map.ndim == 3:\n",
    "            depth_map = cv2.cvtColor(depth_map, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        left_eye_image = shift_pixels(color_image, depth_map, 1, scale_factor)\n",
    "        right_eye_image = shift_pixels(color_image, depth_map, -1, scale_factor)\n",
    "\n",
    "        if not os.path.exists(os.path.join(output_dir,'leftEye')):\n",
    "            os.makedirs(os.path.join(output_dir,'leftEye'))\n",
    "        if not os.path.exists(os.path.join(output_dir,'rightEye')):\n",
    "            os.makedirs(os.path.join(output_dir,'rightEye'))\n",
    "        \n",
    "        left_eye_output_path = os.path.join(output_dir, f'leftEye/leftEye{frame_number}.jpg')\n",
    "        right_eye_output_path = os.path.join(output_dir, f'rightEye/rightEye{frame_number}.jpg')\n",
    "\n",
    "        # Save the left and right eye images\n",
    "        cv2.imwrite(left_eye_output_path, left_eye_image)\n",
    "        cv2.imwrite(right_eye_output_path, right_eye_image)\n",
    "\n",
    "        print(f\"Processed and saved images for frame {frame_number}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception in process_image_pair for frame {frame_number}: {e}\")\n",
    "\n",
    "\n",
    "# Setup directories and process images\n",
    "input_directory = \"C:/Users/abahrema/Documents/Tools/sbs-generator/datasets/d0/rgbd_in\"\n",
    "output_directory = \"C:/Users/abahrema/Documents/Tools/sbs-generator/datasets/d0/scratch_test\"\n",
    "print(\"Creating output directory if it doesn't exist.\")\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "print(\"Reading color images from the input directory.\")\n",
    "\n",
    "color_images = sorted([f for f in os.listdir(input_directory) if f.startswith('color')])\n",
    "depth_images = sorted([f for f in os.listdir(input_directory) if f.startswith('depth')])\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=os.cpu_count() - 1) as executor:\n",
    "    futures = []\n",
    "    for color_image, depth_image in zip(color_images, depth_images):\n",
    "        color_image_path = os.path.join(input_directory, color_image)\n",
    "        depth_image_path = os.path.join(input_directory, depth_image)\n",
    "        frame_number = color_image.split('color')[1].split('.')[0]\n",
    "        futures.append(executor.submit(process_image_pair, color_image_path, depth_image_path, output_directory, frame_number, 0.1))\n",
    "\n",
    "    # Progress tracking\n",
    "    for f in tqdm(concurrent.futures.as_completed(futures), total=len(futures)):\n",
    "        pass\n",
    "\n",
    "print(\"Image processing completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0e0726",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def process_images(input_dir, output_dir, scale_factor):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    color_images = sorted([f for f in os.listdir(input_dir) if f.startswith('color')])\n",
    "    depth_images = sorted([f for f in os.listdir(input_dir) if f.startswith('depth')])\n",
    "\n",
    "    for color_image_path, depth_image_path in zip(color_images, depth_images):\n",
    "        color_image = cv2.imread(os.path.join(input_dir, color_image_path))\n",
    "        depth_map = cv2.imread(os.path.join(input_dir, depth_image_path), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if color_image is None:\n",
    "            print(f\"Error: Color image not found at {os.path.join(input_dir, color_image_path)}\")\n",
    "            continue\n",
    "\n",
    "        if depth_map is None:\n",
    "            print(f\"Error: Depth map not found at {os.path.join(input_dir, depth_image_path)}\")\n",
    "            continue\n",
    "\n",
    "        # Function to shift pixels based on depth map\n",
    "        def shift_pixels(image, depth_map, direction):\n",
    "            shifted_image = np.zeros_like(image)\n",
    "            for y in range(image.shape[0]):\n",
    "                for x in range(image.shape[1]):\n",
    "                    disparity = calculate_disparity(depth_map[y, x])\n",
    "                    new_x = x + disparity * direction\n",
    "                    if 0 <= new_x < image.shape[1]:\n",
    "                        shifted_image[y, new_x] = image[y, x]\n",
    "            return shifted_image\n",
    "\n",
    "        # Calculate disparity (example function, adjust as needed)\n",
    "        def calculate_disparity(depth_value):\n",
    "            # Simple linear mapping, adjust the scale factor as needed\n",
    "            return int(depth_value * scale_factor)\n",
    "\n",
    "        # Create left and right eye images\n",
    "        left_eye_image = shift_pixels(color_image, depth_map, 1)\n",
    "        right_eye_image = shift_pixels(color_image, depth_map, -1)\n",
    "\n",
    "        frame_number = color_image_path.split('color')[1].split('.')[0]\n",
    "        \n",
    "        if not os.path.exists(os.path.join(output_dir,'leftEye')):\n",
    "            os.makedirs(os.path.join(output_dir,'leftEye'))\n",
    "        if not os.path.exists(os.path.join(output_dir,'rightEye')):\n",
    "            os.makedirs(os.path.join(output_dir,'rightEye'))\n",
    "        \n",
    "        left_eye_output_path = os.path.join(output_dir, f'leftEye/leftEye{frame_number}.jpg')\n",
    "        right_eye_output_path = os.path.join(output_dir, f'rightEye/rightEye{frame_number}.jpg')\n",
    "\n",
    "        # Save the left and right eye images\n",
    "        cv2.imwrite(left_eye_output_path, left_eye_image)\n",
    "        cv2.imwrite(right_eye_output_path, right_eye_image)\n",
    "\n",
    "        print(f\"Processed frame {frame_number}.\")\n",
    "\n",
    "# Example usage\n",
    "stereo_input_dir =  dataset_directory + \"rgbd_in/\"\n",
    "stereo_output_dir = dataset_directory + \"stereo_out_frames/\"\n",
    "os.makedirs(stereo_input_dir, exist_ok=True)\n",
    "os.makedirs(stereo_output_dir, exist_ok=True)\n",
    "process_images(stereo_input_dir, stereo_output_dir, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a73f16-eb90-4a03-a176-bbc1621f3172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should work, need to test more.\n",
    "%time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_disparity(depth_value, scale_factor):\n",
    "    return int(depth_value * scale_factor)\n",
    "\n",
    "def shift_pixels(image, depth_map, direction, scale_factor):\n",
    "    shifted_image = np.zeros_like(image)\n",
    "    for y in range(image.shape[0]):\n",
    "        for x in range(image.shape[1]):\n",
    "            disparity = calculate_disparity(depth_map[y, x], scale_factor)\n",
    "            new_x = x + disparity * direction\n",
    "            if 0 <= new_x < image.shape[1]:\n",
    "                shifted_image[y, new_x] = image[y, x]\n",
    "    return shifted_image\n",
    "\n",
    "def process_single_image_pair(args):\n",
    "    color_image_path, depth_image_path, input_dir, output_dir, scale_factor = args\n",
    "    color_image = cv2.imread(os.path.join(input_dir, color_image_path))\n",
    "    depth_map = cv2.imread(os.path.join(input_dir, depth_image_path), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if color_image is None or depth_map is None:\n",
    "        return f\"Error: Image not found for {color_image_path} or {depth_image_path}\"\n",
    "\n",
    "    left_eye_image = shift_pixels(color_image, depth_map, 1, scale_factor)\n",
    "    right_eye_image = shift_pixels(color_image, depth_map, -1, scale_factor)\n",
    "\n",
    "    frame_number = color_image_path.split('color')[1].split('.')[0]\n",
    "\n",
    "    left_eye_output_path = os.path.join(output_dir, 'leftEye', f'leftEye{frame_number}.jpg')\n",
    "    right_eye_output_path = os.path.join(output_dir, 'rightEye', f'rightEye{frame_number}.jpg')\n",
    "\n",
    "    cv2.imwrite(left_eye_output_path, left_eye_image)\n",
    "    cv2.imwrite(right_eye_output_path, right_eye_image)\n",
    "\n",
    "    return f\"Processed frame {frame_number}\"\n",
    "\n",
    "def process_images(input_dir, output_dir, scale_factor):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    color_images = sorted([f for f in os.listdir(input_dir) if f.startswith('color')])\n",
    "    depth_images = sorted([f for f in os.listdir(input_dir) if f.startswith('depth')])\n",
    "\n",
    "    image_pairs = list(zip(color_images, depth_images))\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        args = [(color_image, depth_image, input_dir, output_dir, scale_factor) for color_image, depth_image in image_pairs]\n",
    "        results = list(tqdm(executor.map(process_single_image_pair, args), total=len(args)))\n",
    "\n",
    "    for result in results:\n",
    "        if result:\n",
    "            print(result)\n",
    "\n",
    "stereo_input_dir = os.path.join(dataset_directory, \"rgbd_in/\")\n",
    "stereo_output_dir = os.path.join(dataset_directory, \"stereo_out_frames/\")\n",
    "os.makedirs(stereo_input_dir, exist_ok=True)\n",
    "os.makedirs(stereo_output_dir, exist_ok=True)\n",
    "print(\"About to process\")\n",
    "process_images(stereo_input_dir, stereo_output_dir, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35adf01f",
   "metadata": {},
   "source": [
    "\n",
    "## Inpainting Process\n",
    "\n",
    "Run the script for inpainting left and right eye images or run the function inside notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8cb281",
   "metadata": {},
   "outputs": [],
   "source": [
    "stereo_output_dir = dataset_directory + \"stereo_out_frames/\"\n",
    "stereo_postprocess_dir = dataset_directory + \"stereo_postprocess_frames/\"\n",
    "os.makedirs(stereo_output_dir, exist_ok=True)\n",
    "os.makedirs(stereo_postprocess_dir, exist_ok=True)\n",
    "\n",
    "!python sbs_inpaint_stereoviews.py {stereo_output_dir} {stereo_postprocess_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e879b8-494b-47f4-9ce0-97fdce6ce769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stable\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "from threading import Lock\n",
    "\n",
    "from skimage.restoration import inpaint_biharmonic\n",
    "from skimage import img_as_float\n",
    "from skimage.color import rgb2gray\n",
    "from tqdm import tqdm\n",
    "\n",
    "# def create_mask_for_black_streaks(image):\n",
    "#     # Convert the image to grayscale\n",
    "#     gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "#     # Use adaptive thresholding to better capture the black streaks\n",
    "#     mask = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 3, 8)\n",
    "    \n",
    "#     # Dilate the mask to include the edges of the black streaks\n",
    "#     kernel = np.ones((5,5), np.uint8)\n",
    "#     mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "    \n",
    "#     return mask\n",
    "\n",
    "def create_mask_for_black_streaks(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    mask = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "    # Ensure mask is binary and of type np.uint8\n",
    "    # mask = np.clip(mask, 0, 255).astype(np.uint8)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def inpaint_black_streaks(image, mask):\n",
    "    try:\n",
    "        # Confirm or adjust image data type\n",
    "        if image.dtype != np.uint8:\n",
    "            print(\"Adjusting image data type to uint8\")\n",
    "            image = np.clip(image, 0, 255).astype(np.uint8)\n",
    "\n",
    "        # Ensure mask is binary and of type np.uint8\n",
    "        if mask.dtype != np.uint8 or np.unique(mask).tolist() not in [[0], [0, 255], [255]]:\n",
    "            print(\"Adjusting mask data type to uint8 and ensuring it is binary\")\n",
    "            mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "        print(\"About to start inpainting with cv2.inpaint\")\n",
    "        inpainted_image = cv2.inpaint(image, mask, inpaintRadius=5, flags=cv2.INPAINT_TELEA)\n",
    "        print(\"Inpainting completed successfully\")\n",
    "\n",
    "        return inpainted_image\n",
    "    except Exception as e:\n",
    "        print(f\"Exception during inpainting: {e}\")\n",
    "        return image\n",
    "\n",
    "\n",
    "# def inpaint_with_scikit(image, mask):\n",
    "#     # Convert image to float range [0, 1]\n",
    "#     image_float = img_as_float(image)  # Converts to float and scales [0, 1]\n",
    "\n",
    "#     # Ensure the mask is a boolean array\n",
    "#     mask_bool = mask.astype(bool)\n",
    "#     print(f\"Image shape: {image_float.shape}\")\n",
    "#     print(f\"Mask shape: {mask.shape}\")\n",
    "#     # Perform inpainting\n",
    "#     inpainted_image = inpaint_biharmonic(image_float, mask_bool, channel_axis=2)\n",
    "#     print(\"passed\")\n",
    "#     # Convert the inpainted image back to uint8 if necessary\n",
    "#     inpainted_image_uint8 = (inpainted_image * 255).astype(np.uint8)\n",
    "\n",
    "#     return inpainted_image_uint8\n",
    "\n",
    "\n",
    "def inpaint_with_scikit(image, mask):\n",
    "    # Convert image to float range [0, 1]\n",
    "    image_float = img_as_float(image)\n",
    "\n",
    "    # Ensure the mask is a boolean array\n",
    "    mask_bool = mask.astype(bool)\n",
    "\n",
    "    if image.ndim == 3:  # Color image\n",
    "        inpainted_channels = []\n",
    "        for i in range(image.shape[2]):  # Iterate over each channel\n",
    "            channel = image_float[:, :, i]\n",
    "            inpainted_channel = inpaint_biharmonic(channel, mask_bool)\n",
    "            inpainted_channels.append(inpainted_channel)\n",
    "        inpainted_image = np.stack(inpainted_channels, axis=-1)\n",
    "    else:  # Grayscale image\n",
    "        inpainted_image = inpaint_biharmonic(image_float, mask_bool)\n",
    "\n",
    "    # Convert the inpainted image back to uint8\n",
    "    inpainted_image_uint8 = (inpainted_image * 255).astype(np.uint8)\n",
    "    return inpainted_image_uint8\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_image_pair(paths, output_dir, frame_number, save_masks, lock):\n",
    "    left_eye_image_path, right_eye_image_path = paths\n",
    "    try:\n",
    "        print(f\"Processing frame {frame_number}\")\n",
    "\n",
    "        left_eye_image = cv2.imread(left_eye_image_path)\n",
    "        right_eye_image = cv2.imread(right_eye_image_path)\n",
    "\n",
    "        if left_eye_image is None or right_eye_image is None:\n",
    "            print(f\"Error: Image not found for frame {frame_number}\")\n",
    "            return\n",
    "\n",
    "        # Print out the data types of the images\n",
    "        # print(f\"Left eye image dtype: {left_eye_image.dtype}\")\n",
    "        # print(f\"Right eye image dtype: {right_eye_image.dtype}\")\n",
    "\n",
    "        # Perform additional processing if needed\n",
    "        if save_masks:\n",
    "            left_eye_mask = create_mask_for_black_streaks(left_eye_image)\n",
    "            right_eye_mask = create_mask_for_black_streaks(right_eye_image)\n",
    "\n",
    "            # Optionally save masks\n",
    "            cv2.imwrite(os.path.join(output_dir, \"leftEyeMask\", f\"leftEyeMask{frame_number}.jpg\"), left_eye_mask)\n",
    "            cv2.imwrite(os.path.join(output_dir, \"rightEyeMask\", f\"rightEyeMask{frame_number}.jpg\"), right_eye_mask)\n",
    "\n",
    "        # Example placeholder for inpainting or other processing\n",
    "        with lock:\n",
    "                print(f\"Acquiring lock for frame {frame_number}\")\n",
    "                left_eye_post = inpaint_with_scikit(left_eye_image, left_eye_mask)\n",
    "                right_eye_post = inpaint_with_scikit(right_eye_image, right_eye_mask)\n",
    "                print(f\"Releasing lock for frame {frame_number}\")\n",
    "        # test_inpainting()\n",
    "        # test_inpainting()\n",
    "\n",
    "        # Save the processed images\n",
    "        # cv2.imwrite(os.path.join(output_dir, \"leftEye\", f\"leftEyePost{frame_number}.jpg\"), left_eye_image)\n",
    "        # cv2.imwrite(os.path.join(output_dir, \"rightEye\", f\"rightEyePost{frame_number}.jpg\"), right_eye_image)\n",
    "        cv2.imwrite(os.path.join(output_dir, \"leftEye\", f\"leftEyePost{frame_number}.jpg\"), left_eye_post)\n",
    "        cv2.imwrite(os.path.join(output_dir, \"rightEye\", f\"rightEyePost{frame_number}.jpg\"), right_eye_post)\n",
    "\n",
    "        print(f\"Completed frame {frame_number}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception processing frame {frame_number}: {e}\")\n",
    "\n",
    "def main_process(input_dir, output_dir, save_masks=False):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    dirs_to_create = [\"leftEye\", \"rightEye\"]\n",
    "    if save_masks:\n",
    "        dirs_to_create += [\"leftEyeMask\", \"rightEyeMask\"]\n",
    "    for dir_name in dirs_to_create:\n",
    "        os.makedirs(os.path.join(output_dir, dir_name), exist_ok=True)\n",
    "\n",
    "    left_path = os.path.join(input_dir, \"leftEye\")\n",
    "    right_path = os.path.join(input_dir, \"rightEye\")\n",
    "    left_eye_images = sorted([os.path.join(left_path, f) for f in os.listdir(left_path) if f.startswith('leftEye')])\n",
    "    right_eye_images = sorted([os.path.join(right_path, f) for f in os.listdir(right_path) if f.startswith('rightEye')])\n",
    "\n",
    "    lock = Lock()  # Create a lock instance\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=os.cpu_count() - 1) as executor:\n",
    "        futures = [executor.submit(process_image_pair, paths, output_dir, idx+1, save_masks, lock)\n",
    "                   for idx, paths in enumerate(zip(left_eye_images, right_eye_images))]\n",
    "\n",
    "        # Progress tracking\n",
    "        list(tqdm(concurrent.futures.as_completed(futures), total=len(futures)))\n",
    "\n",
    "    print(\"All image processing completed.\")\n",
    "\n",
    "# Example usage\n",
    "input_directory = \"C:/Users/abahrema/Documents/Tools/sbs-generator/datasets/d0/scratch_test\"\n",
    "output_directory = \"C:/Users/abahrema/Documents/Tools/sbs-generator/datasets/d0/scratch_test_post_patient\"\n",
    "os.makedirs(input_directory, exist_ok=True)\n",
    "os.makedirs(output_directory, exist_ok=True)    \n",
    "main_process(input_directory, output_directory, save_masks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162d9f9e-0fc2-455c-8f85-a919b6514d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stable mask generator\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Path to the color image\n",
    "color_image_path = r\"C:\\Users\\abahrema\\Documents\\Tools\\sbs-generator\\datasets\\d0\\scratch_test_savedShifts\\leftEye\\leftEye0.jpg\"\n",
    "\n",
    "# Path to the text file containing black pixel indexes\n",
    "black_pixels_file_path = r\"C:\\Users\\abahrema\\Documents\\Tools\\sbs-generator\\datasets\\d0\\scratch_test_savedShifts\\color0_significant_shifts.txt\"\n",
    "\n",
    "# Load the color image\n",
    "color_image = cv2.imread(color_image_path)\n",
    "\n",
    "# Read the black pixel indexes from the file\n",
    "with open(black_pixels_file_path, 'r') as file:\n",
    "    black_pixel_indexes = [int(line.strip()) for line in file.readlines()]\n",
    "\n",
    "# Initialize the mask image with zeros (all black)\n",
    "mask_image = np.zeros(color_image.shape[:2], dtype=np.uint8)\n",
    "\n",
    "# Image dimensions\n",
    "height, width = color_image.shape[:2]\n",
    "\n",
    "# Mark the black pixels in the mask image\n",
    "for index in black_pixel_indexes:\n",
    "    y = index // width\n",
    "    x = index % width\n",
    "    mask_image[y, x] = 255  # Mark as white in the mask\n",
    "\n",
    "# Path to save the mask image\n",
    "mask_image_path = r\"C:\\Users\\abahrema\\Documents\\Tools\\sbs-generator\\datasets\\d0\\scratch_test_savedShifts\\maskLeftEye0_take3.jpg\"\n",
    "\n",
    "# Save the mask image\n",
    "cv2.imwrite(mask_image_path, mask_image)\n",
    "\n",
    "print(f\"Mask image saved to {mask_image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b621a2c8-35b4-467f-b84b-8d6012bfcb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "about to perform inpaint operation\n",
      "inpaint complete\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stable inpaint and touch up\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import io, color\n",
    "from skimage.morphology import binary_dilation, disk\n",
    "\n",
    "def inpaint_image_with_mask(color_image_path, mask_image_path, inpaint_radius=3):\n",
    "    \"\"\"\n",
    "    Inpaints a color image using a mask image.\n",
    "\n",
    "    Parameters:\n",
    "    - color_image_path: Path to the color image.\n",
    "    - mask_image_path: Path to the mask image where white pixels indicate areas to inpaint.\n",
    "    - inpaint_radius: Radius of a circular neighborhood of each point inpainted that is considered by the algorithm.\n",
    "\n",
    "    Returns:\n",
    "    - inpainted_image: The inpainted image as a NumPy array.\n",
    "    \"\"\"    \n",
    "    # Load the color image and mask\n",
    "    color_image = cv2.imread(color_image_path)\n",
    "    mask = cv2.imread(mask_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Ensure the mask is binary\n",
    "    # _, mask_binary = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "    # mask_binary = cv2.adaptiveThreshold(mask, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 3, 8)\n",
    "    mask_binary = cv2.adaptiveThreshold(mask, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 3, 8)\n",
    "    # Perform inpainting\n",
    "    print(\"about to perform inpaint operation\")\n",
    "    # inpainted_image = cv2.inpaint(color_image, mask_binary, inpaint_radius, cv2.INPAINT_TELEA)\n",
    "    inpainted_image = cv2.inpaint(color_image, mask_binary, 3, cv2.INPAINT_TELEA)\n",
    "\n",
    "    # Convert image to grayscale\n",
    "    gray_image = color.rgb2gray(inpainted_image)\n",
    "    threshold = 0.05  # A value close to 0 to capture black\n",
    "    binary_mask = gray_image < threshold    \n",
    "    # Dilate the mask to ensure all black or near black pixels are included\n",
    "    dilated_mask = binary_dilation(binary_mask, disk(1))    \n",
    "    inpainted_image = cv2.inpaint(inpainted_image, dilated_mask.astype(np.uint8), 3, cv2.INPAINT_TELEA)\n",
    "    print(\"inpaint complete\")\n",
    "    return inpainted_image\n",
    "\n",
    "# Example usage\n",
    "color_image_path = r\"C:\\Users\\abahrema\\Documents\\Tools\\sbs-generator\\datasets\\d0\\scratch_test\\leftEye\\leftEye1.jpg\"\n",
    "mask_image_path  = r\"C:\\Users\\abahrema\\Documents\\Tools\\sbs-generator\\datasets\\d0\\scratch_test_savedShifts\\maskLeftEye0_take3.jpg\"\n",
    "inpaint_radius = 3  # Adjust as needed\n",
    "\n",
    "# Perform inpainting\n",
    "inpainted_image = inpaint_image_with_mask(color_image_path, mask_image_path, inpaint_radius)\n",
    "\n",
    "# Save or display the inpainted image\n",
    "output_image_path = r\"C:\\Users\\abahrema\\Documents\\Tools\\sbs-generator\\datasets\\d0\\scratch_test_savedShifts\\inpainted0_take7.jpg\"\n",
    "cv2.imwrite(output_image_path, inpainted_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdf8add-274f-42ca-b0ed-f126979e9cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def generate_and_save_mask(image_path, black_pixels_file_path, output_dir):\n",
    "    # Load the color image\n",
    "    color_image = cv2.imread(image_path)\n",
    "    if color_image is None:\n",
    "        raise ValueError(f\"Image not found at the path: {image_path}\")\n",
    "    \n",
    "    # Initialize mask with ones (not black pixels)\n",
    "    mask = np.ones(color_image.shape[:2], dtype=np.uint8) * 255\n",
    "\n",
    "    # Load black pixel indices from the file and update the mask\n",
    "    with open(black_pixels_file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            index = int(line.strip())\n",
    "            y = index // color_image.shape[1]\n",
    "            x = index % color_image.shape[1]\n",
    "            mask[y, x] = 0  # Mark as black in the mask\n",
    "\n",
    "    # Save the mask image\n",
    "    mask_image_path = os.path.join(output_dir, 'maskLeftEye0_take2.jpg')\n",
    "    cv2.imwrite(mask_image_path, mask)\n",
    "    print(f\"Mask image saved at {mask_image_path}\")\n",
    "\n",
    "# Call the function with your paths (replace with your actual paths)\n",
    "color_image_path = r\"C:\\Users\\abahrema\\Documents\\Tools\\sbs-generator\\datasets\\d0\\scratch_test_savedShifts\\leftEye\\leftEye0.jpg\"\n",
    "black_pixels_file_path = r\"C:\\Users\\abahrema\\Documents\\Tools\\sbs-generator\\datasets\\d0\\scratch_test_savedShifts\\color0_black_pixels.txt\"\n",
    "output_dir = r\"C:\\Users\\abahrema\\Documents\\Tools\\sbs-generator\\datasets\\d0\\scratch_test_savedShifts\"\n",
    "generate_and_save_mask(color_image_path, black_pixels_file_path, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56acc662",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def create_mask_for_black_streaks(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Use adaptive thresholding to better capture the black streaks\n",
    "    mask = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 3, 8)\n",
    "    \n",
    "    # Dilate the mask to include the edges of the black streaks\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def inpaint_black_streaks(image, mask):\n",
    "    # Inpaint the black streaks in the image\n",
    "    inpainted_image = cv2.inpaint(image, mask, 5, cv2.INPAINT_TELEA)\n",
    "    \n",
    "    return inpainted_image\n",
    "\n",
    "def process_images(input_dir, output_dir, save_masks=False):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    if not os.path.exists(os.path.join(output_dir,'leftEye')):\n",
    "        os.makedirs(os.path.join(output_dir,'leftEye'))\n",
    "    if not os.path.exists(os.path.join(output_dir,'rightEye')):\n",
    "        os.makedirs(os.path.join(output_dir,'rightEye'))\n",
    "    \n",
    "    if save_masks:\n",
    "        if not os.path.exists(os.path.join(output_dir,'leftEyeMask')):\n",
    "            os.makedirs(os.path.join(output_dir,'leftEyeMask'))\n",
    "        if not os.path.exists(os.path.join(output_dir,'rightEyeMask')):\n",
    "            os.makedirs(os.path.join(output_dir,'rightEyeMask'))\n",
    "\n",
    "    left_path = input_dir + \"leftEye/\"\n",
    "    right_path = input_dir + \"rightEye/\"\n",
    "    left_eye_images = sorted([f for f in os.listdir(left_path) if f.startswith('leftEye')])\n",
    "    right_eye_images = sorted([f for f in os.listdir(right_path) if f.startswith('rightEye')])\n",
    "\n",
    "    for left_eye_image_path, right_eye_image_path in zip(left_eye_images, right_eye_images):\n",
    "        left_eye_image = cv2.imread(os.path.join(left_path, left_eye_image_path))\n",
    "        right_eye_image = cv2.imread(os.path.join(right_path, right_eye_image_path))\n",
    "\n",
    "        if left_eye_image is None or right_eye_image is None:\n",
    "            print(f\"Error: Image not found at {os.path.join(input_dir, left_eye_image_path)} or {os.path.join(input_dir, right_eye_image_path)}\")\n",
    "            continue\n",
    "\n",
    "        # Create masks for the black streaks in both left and right eye images\n",
    "        left_eye_mask = create_mask_for_black_streaks(left_eye_image)\n",
    "        right_eye_mask = create_mask_for_black_streaks(right_eye_image)\n",
    "\n",
    "        # Inpaint the black streaks in both left and right eye images\n",
    "        # left_eye_post = inpaint_black_streaks(left_eye_image, left_eye_mask)\n",
    "        # right_eye_post = inpaint_black_streaks(right_eye_image, right_eye_mask)\n",
    "\n",
    "        frame_number = left_eye_image_path.split('leftEye')[1].split('.')[0]\n",
    "        left_eye_post_output_path = os.path.join(output_dir + \"leftEye/\", f'leftEyePost{frame_number}.jpg')\n",
    "        right_eye_post_output_path = os.path.join(output_dir + \"rightEye/\", f'rightEyePost{frame_number}.jpg')\n",
    "        # Save the processed images and masks\n",
    "        # cv2.imwrite(left_eye_post_output_path, left_eye_post)\n",
    "        # cv2.imwrite(right_eye_post_output_path, right_eye_post)\n",
    "        \n",
    "        if (save_masks):\n",
    "            left_eye_mask_output_path = os.path.join(output_dir + \"leftEyeMask/\", f'leftEyeMask{frame_number}.jpg')\n",
    "            right_eye_mask_output_path = os.path.join(output_dir + \"rightEyeMask/\", f'rightEyeMask{frame_number}.jpg')\n",
    "            cv2.imwrite(left_eye_mask_output_path, left_eye_mask)\n",
    "            cv2.imwrite(right_eye_mask_output_path, right_eye_mask)\n",
    "\n",
    "        print(f\"Processed frame {frame_number}.\")\n",
    "\n",
    "                          \n",
    "stereo_output_dir = dataset_directory + \"stereo_out_frames/\"\n",
    "stereo_postprocess_dir = dataset_directory + \"stereo_postprocess_frames/\"\n",
    "os.makedirs(stereo_output_dir, exist_ok=True)\n",
    "os.makedirs(stereo_postprocess_dir, exist_ok=True)                          \n",
    "# Example usage\n",
    "process_images(stereo_output_dir, stereo_postprocess_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adc9976",
   "metadata": {},
   "source": [
    "\n",
    "## Create Videos from Images\n",
    "\n",
    "Use ffmpeg to create left and right eye videos. \n",
    "\n",
    "**Note** what the appropriate frame rate should be based on your input video.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83851e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_eye_dir = dataset_directory + \"stereo_postprocess_frames/\" + \"leftEye/\"\n",
    "right_eye_dir = dataset_directory + \"stereo_postprocess_frames/\" + \"rightEye/\"\n",
    "os.makedirs(left_eye_dir, exist_ok=True)\n",
    "os.makedirs(right_eye_dir, exist_ok=True)\n",
    "left_eye_dir += \"leftEyePost%d.jpg\"\n",
    "right_eye_dir += \"rightEyePost%d.jpg\"\n",
    "\n",
    "left_eye_vid = dataset_directory + \"left_eye.mp4\"\n",
    "right_eye_vid = dataset_directory + \"right_eye.mp4\"\n",
    "\n",
    "\n",
    "!ffmpeg -framerate 24 -i {left_eye_dir} -c:v libx264 -pix_fmt yuv420p -vf \"fps=24\" {left_eye_vid}\n",
    "!ffmpeg -framerate 24 -i {right_eye_dir} -c:v libx264 -pix_fmt yuv420p -vf \"fps=24\" {right_eye_vid}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1971f9",
   "metadata": {},
   "source": [
    "\n",
    "## Merge Videos and Inject Metadata\n",
    "\n",
    "Combine the left and right eye videos into an SBS video and inject 3D metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b2c7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_eye_vid = dataset_directory + \"left_eye.mp4\"\n",
    "right_eye_vid = dataset_directory + \"right_eye.mp4\"\n",
    "output_vid = dataset_directory + \"output.SBS.mp4\"\n",
    "\n",
    "!ffmpeg -i {left_eye_vid} -i {right_eye_vid} -filter_complex \"[0:v][1:v]hstack=inputs=2[v]\" -map \"[v]\" {output_vid}\n",
    "!ffmpeg -i {output_vid} -vf \"scale=2*iw:ih\" -c:v libx264 -x264opts \"frame-packing=3\" -aspect 2:1 {final_video_filename}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4943eb",
   "metadata": {},
   "source": [
    "## Upload SBS video to Quest headset\n",
    "\n",
    "First register device connection, then push file, and lastly force the file system to update without restarting the device.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3155fb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!adb devices\n",
    "!adb push {final_video_filename} /sdcard/Movies/\n",
    "!adb shell am force-stop com.android.providers.media.module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f75dc8",
   "metadata": {},
   "source": [
    "\n",
    "## Cleanup and Finalization\n",
    "\n",
    "(Optional) Cleanup temporary files and display/export the final video path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38160454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example cleanup (adjust as needed)\n",
    "\n",
    "#rgbd frame directories\n",
    "rgbd_frames = dataset_directory + 'rgbd_in/'\n",
    "#stereo directories\n",
    "stereo_input_dir =  dataset_directory + \"input_frames/\"\n",
    "stereo_output_dir = dataset_directory + \"stereo_out_frames/\"\n",
    "#inpainting directories\n",
    "stereo_postprocess_dir = dataset_directory + \"stereo_postprocess_frames/\"\n",
    "\n",
    "#video directories\n",
    "left_eye_vid = dataset_directory + \"left_eye.mp4\"\n",
    "right_eye_vid = dataset_directory + \"right_eye.mp4\"\n",
    "output_vid = dataset_directory + \"output.SBS.mp4\"\n",
    "\n",
    "# delete all directories and videos\n",
    "!rm -rf {rgbd_frames}\n",
    "!rm -rf {stereo_input_dir}\n",
    "!rm -rf {stereo_output_dir}\n",
    "!rm -rf {stereo_postprocess_dir}\n",
    "!rm {left_eye_vid} {right_eye_vid} {output_vid}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Depth-Anything",
   "language": "python",
   "name": "depth-anything"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
