{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cee2917f",
   "metadata": {},
   "source": [
    "\n",
    "# SBS 3D Video Generation Pipeline\n",
    "\n",
    "This notebook outlines the process of converting a monocular video into a side-by-side (SBS) 3D video.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e231e45a",
   "metadata": {},
   "source": [
    "\n",
    "## Setup and Preparation\n",
    "\n",
    "Import necessary libraries and define the input video path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ca7e718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Define the path to the input video\n",
    "input_video_path = 'data_in/input.mp4'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caf08b7",
   "metadata": {},
   "source": [
    "\n",
    "## Extract Frames from Video\n",
    "\n",
    "Use ffmpeg to extract frames from the input video.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d488a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!ffmpeg -i {input_video_path} -q:v 2 datasets/data_in/frame%d.jpg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321b274d",
   "metadata": {},
   "source": [
    "\n",
    "## Generate Depth Images\n",
    "\n",
    "(Placeholder: Run the depth estimation model/tool here.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb9eaab",
   "metadata": {},
   "source": [
    "\n",
    "## Image Preprocessing\n",
    "\n",
    "Rename and pair images as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d702eabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for renaming images (adjust according to your script)\n",
    "!python sbs_rename_directory.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15957937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "source_dir = \"./datasets/data_in/depth\"\n",
    "target_prefix = \"depth\"\n",
    "\n",
    "def get_frame_number(filename):\n",
    "    return int(filename.split(\"depth\")[1].split(\".\")[0])\n",
    "\n",
    "\n",
    "file_list = os.listdir(source_dir)\n",
    "frame_files = sorted([f for f in file_list if f.startswith(\"depth\") and f.endswith(\".png\")], key=get_frame_number)\n",
    "counter = 0\n",
    "\n",
    "for filename in frame_files:\n",
    "    new_name = f\"{target_prefix}{counter}.png\"\n",
    "    os.rename(os.path.join(source_dir, filename), os.path.join(source_dir, new_name))\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca376732",
   "metadata": {},
   "source": [
    "\n",
    "## Generate Stereo Views\n",
    "\n",
    "Run the script to generate left and right eye views.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d21ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python sbs_generate_stereoviews.py data_in/ data_out/  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0e0726",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed frame 0.\n",
      "Processed frame 1.\n",
      "Processed frame 10.\n",
      "Processed frame 100.\n",
      "Processed frame 101.\n",
      "Processed frame 102.\n",
      "Processed frame 103.\n",
      "Processed frame 104.\n",
      "Processed frame 105.\n",
      "Processed frame 106.\n",
      "Processed frame 11.\n",
      "Processed frame 12.\n",
      "Processed frame 13.\n",
      "Processed frame 14.\n",
      "Processed frame 15.\n",
      "Processed frame 16.\n",
      "Processed frame 17.\n",
      "Processed frame 18.\n",
      "Processed frame 19.\n",
      "Processed frame 2.\n",
      "Processed frame 20.\n",
      "Processed frame 21.\n",
      "Processed frame 22.\n",
      "Processed frame 23.\n",
      "Processed frame 24.\n",
      "Processed frame 25.\n",
      "Processed frame 26.\n",
      "Processed frame 27.\n",
      "Processed frame 28.\n",
      "Processed frame 29.\n",
      "Processed frame 3.\n",
      "Processed frame 30.\n",
      "Processed frame 31.\n",
      "Processed frame 32.\n",
      "Processed frame 33.\n",
      "Processed frame 34.\n",
      "Processed frame 35.\n",
      "Processed frame 36.\n",
      "Processed frame 37.\n",
      "Processed frame 38.\n",
      "Processed frame 39.\n",
      "Processed frame 4.\n",
      "Processed frame 40.\n",
      "Processed frame 41.\n",
      "Processed frame 42.\n",
      "Processed frame 43.\n",
      "Processed frame 44.\n",
      "Processed frame 45.\n",
      "Processed frame 46.\n",
      "Processed frame 47.\n",
      "Processed frame 48.\n",
      "Processed frame 49.\n",
      "Processed frame 5.\n",
      "Processed frame 50.\n",
      "Processed frame 51.\n",
      "Processed frame 52.\n",
      "Processed frame 53.\n",
      "Processed frame 54.\n",
      "Processed frame 55.\n",
      "Processed frame 56.\n",
      "Processed frame 57.\n",
      "Processed frame 58.\n",
      "Processed frame 59.\n",
      "Processed frame 6.\n",
      "Processed frame 60.\n",
      "Processed frame 61.\n",
      "Processed frame 62.\n",
      "Processed frame 63.\n",
      "Processed frame 64.\n",
      "Processed frame 65.\n",
      "Processed frame 66.\n",
      "Processed frame 67.\n",
      "Processed frame 68.\n",
      "Processed frame 69.\n",
      "Processed frame 7.\n",
      "Processed frame 70.\n",
      "Processed frame 71.\n",
      "Processed frame 72.\n",
      "Processed frame 73.\n",
      "Processed frame 74.\n",
      "Processed frame 75.\n",
      "Processed frame 76.\n",
      "Processed frame 77.\n",
      "Processed frame 78.\n",
      "Processed frame 79.\n",
      "Processed frame 8.\n",
      "Processed frame 80.\n",
      "Processed frame 81.\n",
      "Processed frame 82.\n",
      "Processed frame 83.\n",
      "Processed frame 84.\n",
      "Processed frame 85.\n",
      "Processed frame 86.\n",
      "Processed frame 87.\n",
      "Processed frame 88.\n",
      "Processed frame 89.\n",
      "Processed frame 9.\n",
      "Processed frame 90.\n",
      "Processed frame 91.\n",
      "Processed frame 92.\n",
      "Processed frame 93.\n",
      "Processed frame 94.\n",
      "Processed frame 95.\n",
      "Processed frame 96.\n",
      "Processed frame 97.\n",
      "Processed frame 98.\n",
      "Processed frame 99.\n",
      "Processed frame 0.\n",
      "Processed frame 1.\n",
      "Processed frame 10.\n",
      "Processed frame 100.\n",
      "Processed frame 101.\n",
      "Processed frame 102.\n",
      "Processed frame 103.\n",
      "Processed frame 104.\n",
      "Processed frame 105.\n",
      "Processed frame 106.\n",
      "Processed frame 11.\n",
      "Processed frame 12.\n",
      "Processed frame 13.\n",
      "Processed frame 14.\n",
      "Processed frame 15.\n",
      "Processed frame 16.\n",
      "Processed frame 17.\n",
      "Processed frame 18.\n",
      "Processed frame 19.\n",
      "Processed frame 2.\n",
      "Processed frame 20.\n",
      "Processed frame 21.\n",
      "Processed frame 22.\n",
      "Processed frame 23.\n",
      "Processed frame 24.\n",
      "Processed frame 25.\n",
      "Processed frame 26.\n",
      "Processed frame 27.\n",
      "Processed frame 28.\n",
      "Processed frame 29.\n",
      "Processed frame 3.\n",
      "Processed frame 30.\n",
      "Processed frame 31.\n",
      "Processed frame 32.\n",
      "Processed frame 33.\n",
      "Processed frame 34.\n",
      "Processed frame 35.\n",
      "Processed frame 36.\n",
      "Processed frame 37.\n",
      "Processed frame 38.\n",
      "Processed frame 39.\n",
      "Processed frame 4.\n",
      "Processed frame 40.\n",
      "Processed frame 41.\n",
      "Processed frame 42.\n",
      "Processed frame 43.\n",
      "Processed frame 44.\n",
      "Processed frame 45.\n",
      "Processed frame 46.\n",
      "Processed frame 47.\n",
      "Processed frame 48.\n",
      "Processed frame 49.\n",
      "Processed frame 5.\n",
      "Processed frame 50.\n",
      "Processed frame 51.\n",
      "Processed frame 52.\n",
      "Processed frame 53.\n",
      "Processed frame 54.\n",
      "Processed frame 55.\n",
      "Processed frame 56.\n",
      "Processed frame 57.\n",
      "Processed frame 58.\n",
      "Processed frame 59.\n",
      "Processed frame 6.\n",
      "Processed frame 60.\n",
      "Processed frame 61.\n",
      "Processed frame 62.\n",
      "Processed frame 63.\n",
      "Processed frame 64.\n",
      "Processed frame 65.\n",
      "Processed frame 66.\n",
      "Processed frame 67.\n",
      "Processed frame 68.\n",
      "Processed frame 69.\n",
      "Processed frame 7.\n",
      "Processed frame 70.\n",
      "Processed frame 71.\n",
      "Processed frame 72.\n",
      "Processed frame 73.\n",
      "Processed frame 74.\n",
      "Processed frame 75.\n",
      "Processed frame 76.\n",
      "Processed frame 77.\n",
      "Processed frame 78.\n",
      "Processed frame 79.\n",
      "Processed frame 8.\n",
      "Processed frame 80.\n",
      "Processed frame 81.\n",
      "Processed frame 82.\n",
      "Processed frame 83.\n",
      "Processed frame 84.\n",
      "Processed frame 85.\n",
      "Processed frame 86.\n",
      "Processed frame 87.\n",
      "Processed frame 88.\n",
      "Processed frame 89.\n",
      "Processed frame 9.\n",
      "Processed frame 90.\n",
      "Processed frame 91.\n",
      "Processed frame 92.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def process_images(input_dir, output_dir, scale_factor):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    color_images = sorted([f for f in os.listdir(input_dir) if f.startswith('color')])\n",
    "    depth_images = sorted([f for f in os.listdir(input_dir) if f.startswith('depth')])\n",
    "\n",
    "    for color_image_path, depth_image_path in zip(color_images, depth_images):\n",
    "        color_image = cv2.imread(os.path.join(input_dir, color_image_path))\n",
    "        depth_map = cv2.imread(os.path.join(input_dir, depth_image_path), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if color_image is None:\n",
    "            print(f\"Error: Color image not found at {os.path.join(input_dir, color_image_path)}\")\n",
    "            continue\n",
    "\n",
    "        if depth_map is None:\n",
    "            print(f\"Error: Depth map not found at {os.path.join(input_dir, depth_image_path)}\")\n",
    "            continue\n",
    "\n",
    "        # Function to shift pixels based on depth map\n",
    "        def shift_pixels(image, depth_map, direction):\n",
    "            shifted_image = np.zeros_like(image)\n",
    "            for y in range(image.shape[0]):\n",
    "                for x in range(image.shape[1]):\n",
    "                    disparity = calculate_disparity(depth_map[y, x])\n",
    "                    new_x = x + disparity * direction\n",
    "                    if 0 <= new_x < image.shape[1]:\n",
    "                        shifted_image[y, new_x] = image[y, x]\n",
    "            return shifted_image\n",
    "\n",
    "        # Calculate disparity (example function, adjust as needed)\n",
    "        def calculate_disparity(depth_value):\n",
    "            # Simple linear mapping, adjust the scale factor as needed\n",
    "            return int(depth_value * scale_factor)\n",
    "\n",
    "        # Create left and right eye images\n",
    "        left_eye_image = shift_pixels(color_image, depth_map, 1)\n",
    "        right_eye_image = shift_pixels(color_image, depth_map, -1)\n",
    "\n",
    "        frame_number = color_image_path.split('color')[1].split('.')[0]\n",
    "        left_eye_output_path = os.path.join(output_dir, f'leftEye/leftEye{frame_number}.jpg')\n",
    "        right_eye_output_path = os.path.join(output_dir, f'rightEye/rightEye{frame_number}.jpg')\n",
    "\n",
    "        # Save the left and right eye images\n",
    "        cv2.imwrite(left_eye_output_path, left_eye_image)\n",
    "        cv2.imwrite(right_eye_output_path, right_eye_image)\n",
    "\n",
    "        print(f\"Processed frame {frame_number}.\")\n",
    "\n",
    "# Example usage\n",
    "process_images('./datasets/data_in/', './datasets/data_out/', 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a55b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def shift_pixels(image, depth_map, direction, scale_factor):\n",
    "    shifted_image = np.zeros_like(image)\n",
    "    for y in range(image.shape[0]):\n",
    "        for x in range(image.shape[1]):\n",
    "            disparity = int(depth_map[y, x] * scale_factor)\n",
    "            new_x = x + disparity * direction\n",
    "            if 0 <= new_x < image.shape[1]:\n",
    "                shifted_image[y, new_x] = image[y, x]\n",
    "    return shifted_image\n",
    "\n",
    "def process_single_image_pair(color_image_path, depth_image_path, input_dir, output_dir, scale_factor):\n",
    "    try:\n",
    "        color_image = cv2.imread(os.path.join(input_dir, color_image_path))\n",
    "        depth_map = cv2.imread(os.path.join(input_dir, depth_image_path), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if color_image is None or depth_map is None:\n",
    "            return f\"Error: Image not found at {os.path.join(input_dir, color_image_path)} or {os.path.join(input_dir, depth_image_path)}\"\n",
    "\n",
    "        left_eye_image = shift_pixels(color_image, depth_map, 1, scale_factor)\n",
    "        right_eye_image = shift_pixels(color_image, depth_map, -1, scale_factor)\n",
    "\n",
    "        frame_number = color_image_path.split('color')[1].split('.')[0]\n",
    "        left_eye_output_path = os.path.join(output_dir, f'leftEye{frame_number}.jpg')\n",
    "        right_eye_output_path = os.path.join(output_dir, f'rightEye{frame_number}.jpg')\n",
    "\n",
    "        cv2.imwrite(left_eye_output_path, left_eye_image)\n",
    "        cv2.imwrite(right_eye_output_path, right_eye_image)\n",
    "\n",
    "        return f\"Processed frame {frame_number}.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error processing {color_image_path}: {e}\"\n",
    "\n",
    "def process_images(input_dir, output_dir, scale_factor):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    color_images = sorted([f for f in os.listdir(input_dir) if f.startswith('color')])\n",
    "    depth_images = sorted([f for f in os.listdir(input_dir) if f.startswith('depth')])\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        futures = [executor.submit(process_single_image_pair, color_image_path, depth_image_path, input_dir, output_dir, scale_factor) for color_image_path, depth_image_path in zip(color_images, depth_images)]\n",
    "\n",
    "    for future in as_completed(futures):\n",
    "        print(future.result())\n",
    "\n",
    "# Example usage\n",
    "process_images('./datasets/data_in/', './datasets/data_out_fast/', 0.05)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35adf01f",
   "metadata": {},
   "source": [
    "\n",
    "## Inpainting Process\n",
    "\n",
    "Run the script for inpainting left and right eye images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8cb281",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python sbs_inpaint_stereoviews.py data_out/ data_out_final/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56acc662",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed frame 0.\n",
      "Processed frame 1.\n",
      "Processed frame 10.\n",
      "Processed frame 100.\n",
      "Processed frame 101.\n",
      "Processed frame 102.\n",
      "Processed frame 103.\n",
      "Processed frame 104.\n",
      "Processed frame 105.\n",
      "Processed frame 106.\n",
      "Processed frame 11.\n",
      "Processed frame 12.\n",
      "Processed frame 13.\n",
      "Processed frame 14.\n",
      "Processed frame 15.\n",
      "Processed frame 16.\n",
      "Processed frame 17.\n",
      "Processed frame 18.\n",
      "Processed frame 19.\n",
      "Processed frame 2.\n",
      "Processed frame 20.\n",
      "Processed frame 21.\n",
      "Processed frame 22.\n",
      "Processed frame 23.\n",
      "Processed frame 24.\n",
      "Processed frame 25.\n",
      "Processed frame 26.\n",
      "Processed frame 27.\n",
      "Processed frame 28.\n",
      "Processed frame 29.\n",
      "Processed frame 3.\n",
      "Processed frame 30.\n",
      "Processed frame 31.\n",
      "Processed frame 32.\n",
      "Processed frame 33.\n",
      "Processed frame 34.\n",
      "Processed frame 35.\n",
      "Processed frame 36.\n",
      "Processed frame 37.\n",
      "Processed frame 38.\n",
      "Processed frame 39.\n",
      "Processed frame 4.\n",
      "Processed frame 40.\n",
      "Processed frame 41.\n",
      "Processed frame 42.\n",
      "Processed frame 43.\n",
      "Processed frame 44.\n",
      "Processed frame 45.\n",
      "Processed frame 46.\n",
      "Processed frame 47.\n",
      "Processed frame 48.\n",
      "Processed frame 49.\n",
      "Processed frame 5.\n",
      "Processed frame 50.\n",
      "Processed frame 51.\n",
      "Processed frame 52.\n",
      "Processed frame 53.\n",
      "Processed frame 54.\n",
      "Processed frame 55.\n",
      "Processed frame 56.\n",
      "Processed frame 57.\n",
      "Processed frame 58.\n",
      "Processed frame 59.\n",
      "Processed frame 6.\n",
      "Processed frame 60.\n",
      "Processed frame 61.\n",
      "Processed frame 62.\n",
      "Processed frame 63.\n",
      "Processed frame 64.\n",
      "Processed frame 65.\n",
      "Processed frame 66.\n",
      "Processed frame 67.\n",
      "Processed frame 68.\n",
      "Processed frame 69.\n",
      "Processed frame 7.\n",
      "Processed frame 70.\n",
      "Processed frame 71.\n",
      "Processed frame 72.\n",
      "Processed frame 73.\n",
      "Processed frame 74.\n",
      "Processed frame 75.\n",
      "Processed frame 76.\n",
      "Processed frame 77.\n",
      "Processed frame 78.\n",
      "Processed frame 79.\n",
      "Processed frame 8.\n",
      "Processed frame 80.\n",
      "Processed frame 81.\n",
      "Processed frame 82.\n",
      "Processed frame 83.\n",
      "Processed frame 84.\n",
      "Processed frame 85.\n",
      "Processed frame 86.\n",
      "Processed frame 87.\n",
      "Processed frame 88.\n",
      "Processed frame 89.\n",
      "Processed frame 9.\n",
      "Processed frame 90.\n",
      "Processed frame 91.\n",
      "Processed frame 92.\n",
      "Processed frame 93.\n",
      "Processed frame 94.\n",
      "Processed frame 95.\n",
      "Processed frame 96.\n",
      "Processed frame 97.\n",
      "Processed frame 98.\n",
      "Processed frame 99.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def create_mask_for_black_streaks(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Use adaptive thresholding to better capture the black streaks\n",
    "    mask = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 3, 8)\n",
    "    \n",
    "    # Dilate the mask to include the edges of the black streaks\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def inpaint_black_streaks(image, mask):\n",
    "    # Inpaint the black streaks in the image\n",
    "    inpainted_image = cv2.inpaint(image, mask, 5, cv2.INPAINT_TELEA)\n",
    "    \n",
    "    return inpainted_image\n",
    "\n",
    "def process_images(input_dir, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    left_path = input_dir + \"leftEye/\"\n",
    "    right_path = input_dir + \"rightEye/\"\n",
    "    left_eye_images = sorted([f for f in os.listdir(left_path) if f.startswith('leftEye')])\n",
    "    right_eye_images = sorted([f for f in os.listdir(right_path) if f.startswith('rightEye')])\n",
    "\n",
    "    for left_eye_image_path, right_eye_image_path in zip(left_eye_images, right_eye_images):\n",
    "        left_eye_image = cv2.imread(os.path.join(left_path, left_eye_image_path))\n",
    "        right_eye_image = cv2.imread(os.path.join(right_path, right_eye_image_path))\n",
    "\n",
    "        if left_eye_image is None or right_eye_image is None:\n",
    "            print(f\"Error: Image not found at {os.path.join(input_dir, left_eye_image_path)} or {os.path.join(input_dir, right_eye_image_path)}\")\n",
    "            continue\n",
    "\n",
    "        # Create masks for the black streaks in both left and right eye images\n",
    "        left_eye_mask = create_mask_for_black_streaks(left_eye_image)\n",
    "        right_eye_mask = create_mask_for_black_streaks(right_eye_image)\n",
    "\n",
    "        # Inpaint the black streaks in both left and right eye images\n",
    "        left_eye_post = inpaint_black_streaks(left_eye_image, left_eye_mask)\n",
    "        right_eye_post = inpaint_black_streaks(right_eye_image, right_eye_mask)\n",
    "\n",
    "        frame_number = left_eye_image_path.split('leftEye')[1].split('.')[0]\n",
    "        left_eye_post_output_path = os.path.join(output_dir + \"leftEye/\", f'leftEyePost{frame_number}.jpg')\n",
    "        right_eye_post_output_path = os.path.join(output_dir + \"rightEye/\", f'rightEyePost{frame_number}.jpg')\n",
    "\n",
    "        # Save the processed images and masks\n",
    "        cv2.imwrite(left_eye_post_output_path, left_eye_post)\n",
    "        cv2.imwrite(right_eye_post_output_path, right_eye_post)\n",
    "\n",
    "        print(f\"Processed frame {frame_number}.\")\n",
    "\n",
    "# Example usage\n",
    "process_images('./datasets/data_out/', './datasets/data_out_post/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adc9976",
   "metadata": {},
   "source": [
    "\n",
    "## Create Videos from Images\n",
    "\n",
    "Use ffmpeg to create left and right eye videos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83851e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 6.0 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.0.40.1)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.0_1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58.  2.100 / 58.  2.100\n",
      "  libavcodec     60.  3.100 / 60.  3.100\n",
      "  libavformat    60.  3.100 / 60.  3.100\n",
      "  libavdevice    60.  1.100 / 60.  1.100\n",
      "  libavfilter     9.  3.100 /  9.  3.100\n",
      "  libswscale      7.  1.100 /  7.  1.100\n",
      "  libswresample   4. 10.100 /  4. 10.100\n",
      "  libpostproc    57.  1.100 / 57.  1.100\n",
      "Input #0, image2, from './datasets/data_out_post/leftEye/leftEyePost%d.jpg':\n",
      "  Duration: 00:00:03.57, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: mjpeg (Baseline), yuvj420p(pc, bt470bg/unknown/unknown), 1280x720 [SAR 1:1 DAR 16:9], 30 fps, 30 tbr, 30 tbn\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mjpeg (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;34m[swscaler @ 0x120180000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x1405b0000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "    Last message repeated 1 timesimes\n",
      "\u001b[1;34m[swscaler @ 0x130108000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;36m[libx264 @ 0x13b606560] \u001b[0musing SAR=1/1\n",
      "\u001b[1;36m[libx264 @ 0x13b606560] \u001b[0musing cpu capabilities: ARMv8 NEON\n",
      "\u001b[1;36m[libx264 @ 0x13b606560] \u001b[0mprofile High, level 3.1, 4:2:0, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x13b606560] \u001b[0m264 - core 164 r3108 31e19f9 - H.264/MPEG-4 AVC codec - Copyleft 2003-2023 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=21 lookahead_threads=3 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'left_eye.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf60.3.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(tv, bt470bg/unknown/unknown, progressive), 1280x720 [SAR 1:1 DAR 16:9], q=2-31, 30 fps, 15360 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc60.3.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=  107 fps=0.0 q=-1.0 Lsize=     784kB time=00:00:03.46 bitrate=1851.5kbits/s speed=7.26x     \n",
      "video:781kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.269945%\n",
      "\u001b[1;36m[libx264 @ 0x13b606560] \u001b[0mframe I:3     Avg QP:21.46  size: 35128\n",
      "\u001b[1;36m[libx264 @ 0x13b606560] \u001b[0mframe P:28    Avg QP:23.25  size: 12215\n",
      "\u001b[1;36m[libx264 @ 0x13b606560] \u001b[0mframe B:76    Avg QP:25.23  size:  4633\n",
      "\u001b[1;36m[libx264 @ 0x13b606560] \u001b[0mconsecutive B-frames:  4.7%  1.9%  0.0% 93.5%\n",
      "\u001b[1;36m[libx264 @ 0x13b606560] \u001b[0mmb I  I16..4: 14.5% 74.9% 10.6%\n",
      "\u001b[1;36m[libx264 @ 0x13b606560] \u001b[0mmb P  I16..4:  7.7% 13.8%  0.5%  P16..4: 40.2% 11.8%  3.6%  0.0%  0.0%    skip:22.5%\n",
      "\u001b[1;36m[libx264 @ 0x13b606560] \u001b[0mmb B  I16..4:  0.6%  0.8%  0.0%  B16..8: 42.8%  4.5%  0.5%  direct: 1.1%  skip:49.7%  L0:46.9% L1:51.2% BI: 1.8%\n",
      "\u001b[1;36m[libx264 @ 0x13b606560] \u001b[0m8x8 transform intra:65.5% inter:81.2%\n",
      "\u001b[1;36m[libx264 @ 0x13b606560] \u001b[0mcoded y,uvDC,uvAC intra: 38.9% 48.2% 5.9% inter: 9.7% 9.5% 0.0%\n",
      "\u001b[1;36m[libx264 @ 0x13b606560] \u001b[0mi16 v,h,dc,p: 16% 46%  9% 30%\n",
      "\u001b[1;36m[libx264 @ 0x13b606560] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 17% 27% 32%  2%  5%  5%  5%  3%  4%\n",
      "\u001b[1;36m[libx264 @ 0x13b606560] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 20% 24% 15%  4% 10%  9%  8%  4%  4%\n",
      "\u001b[1;36m[libx264 @ 0x13b606560] \u001b[0mi8c dc,h,v,p: 55% 29% 13%  3%\n",
      "\u001b[1;36m[libx264 @ 0x13b606560] \u001b[0mWeighted P-Frames: Y:3.6% UV:0.0%\n",
      "\u001b[1;36m[libx264 @ 0x13b606560] \u001b[0mref P L0: 67.5% 10.4% 17.5%  4.4%  0.2%\n",
      "\u001b[1;36m[libx264 @ 0x13b606560] \u001b[0mref B L0: 89.4%  9.2%  1.4%\n",
      "\u001b[1;36m[libx264 @ 0x13b606560] \u001b[0mref B L1: 95.0%  5.0%\n",
      "\u001b[1;36m[libx264 @ 0x13b606560] \u001b[0mkb/s:1793.21\n",
      "ffmpeg version 6.0 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.0.40.1)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.0_1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58.  2.100 / 58.  2.100\n",
      "  libavcodec     60.  3.100 / 60.  3.100\n",
      "  libavformat    60.  3.100 / 60.  3.100\n",
      "  libavdevice    60.  1.100 / 60.  1.100\n",
      "  libavfilter     9.  3.100 /  9.  3.100\n",
      "  libswscale      7.  1.100 /  7.  1.100\n",
      "  libswresample   4. 10.100 /  4. 10.100\n",
      "  libpostproc    57.  1.100 / 57.  1.100\n",
      "Input #0, image2, from './datasets/data_out_post/rightEye/rightEyePost%d.jpg':\n",
      "  Duration: 00:00:03.57, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: mjpeg (Baseline), yuvj420p(pc, bt470bg/unknown/unknown), 1280x720 [SAR 1:1 DAR 16:9], 30 fps, 30 tbr, 30 tbn\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mjpeg (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;34m[swscaler @ 0x1401b0000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x130008000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x1401b0000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x150688000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;36m[libx264 @ 0x148706ae0] \u001b[0musing SAR=1/1\n",
      "\u001b[1;36m[libx264 @ 0x148706ae0] \u001b[0musing cpu capabilities: ARMv8 NEON\n",
      "\u001b[1;36m[libx264 @ 0x148706ae0] \u001b[0mprofile High, level 3.1, 4:2:0, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x148706ae0] \u001b[0m264 - core 164 r3108 31e19f9 - H.264/MPEG-4 AVC codec - Copyleft 2003-2023 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=21 lookahead_threads=3 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'right_eye.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf60.3.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(tv, bt470bg/unknown/unknown, progressive), 1280x720 [SAR 1:1 DAR 16:9], q=2-31, 30 fps, 15360 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc60.3.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame=    0 fps=0.0 q=0.0 size=       0kB time=-577014:32:22.77 bitrate=  -0.0kbits/s speed=N/A    \r",
      "frame=  107 fps=0.0 q=-1.0 Lsize=     803kB time=00:00:03.46 bitrate=1898.2kbits/s speed=7.15x    \r\n",
      "video:801kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.263294%\r\n",
      "\u001b[1;36m[libx264 @ 0x148706ae0] \u001b[0mframe I:3     Avg QP:21.59  size: 34824\r\n",
      "\u001b[1;36m[libx264 @ 0x148706ae0] \u001b[0mframe P:28    Avg QP:23.36  size: 12306\r\n",
      "\u001b[1;36m[libx264 @ 0x148706ae0] \u001b[0mframe B:76    Avg QP:25.14  size:  4877\r\n",
      "\u001b[1;36m[libx264 @ 0x148706ae0] \u001b[0mconsecutive B-frames:  4.7%  1.9%  0.0% 93.5%\r\n",
      "\u001b[1;36m[libx264 @ 0x148706ae0] \u001b[0mmb I  I16..4: 14.6% 75.3% 10.1%\r\n",
      "\u001b[1;36m[libx264 @ 0x148706ae0] \u001b[0mmb P  I16..4:  7.3% 13.5%  0.5%  P16..4: 40.9% 11.8%  3.7%  0.0%  0.0%    skip:22.2%\r\n",
      "\u001b[1;36m[libx264 @ 0x148706ae0] \u001b[0mmb B  I16..4:  0.6%  0.8%  0.0%  B16..8: 43.1%  4.7%  0.6%  direct: 1.2%  skip:49.0%  L0:47.5% L1:50.6% BI: 1.8%\r\n",
      "\u001b[1;36m[libx264 @ 0x148706ae0] \u001b[0m8x8 transform intra:66.3% inter:81.3%\r\n",
      "\u001b[1;36m[libx264 @ 0x148706ae0] \u001b[0mcoded y,uvDC,uvAC intra: 39.1% 47.8% 5.3% inter: 10.3% 10.0% 0.0%\r\n",
      "\u001b[1;36m[libx264 @ 0x148706ae0] \u001b[0mi16 v,h,dc,p: 15% 44%  9% 31%\r\n",
      "\u001b[1;36m[libx264 @ 0x148706ae0] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 17% 27% 32%  2%  5%  5%  5%  3%  4%\r\n",
      "\u001b[1;36m[libx264 @ 0x148706ae0] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 20% 24% 16%  5% 10%  9%  9%  4%  4%\r\n",
      "\u001b[1;36m[libx264 @ 0x148706ae0] \u001b[0mi8c dc,h,v,p: 55% 29% 13%  3%\r\n",
      "\u001b[1;36m[libx264 @ 0x148706ae0] \u001b[0mWeighted P-Frames: Y:3.6% UV:0.0%\r\n",
      "\u001b[1;36m[libx264 @ 0x148706ae0] \u001b[0mref P L0: 65.7% 10.3% 18.7%  5.1%  0.2%\r\n",
      "\u001b[1;36m[libx264 @ 0x148706ae0] \u001b[0mref B L0: 88.7%  9.7%  1.6%\r\n",
      "\u001b[1;36m[libx264 @ 0x148706ae0] \u001b[0mref B L1: 94.6%  5.4%\r\n",
      "\u001b[1;36m[libx264 @ 0x148706ae0] \u001b[0mkb/s:1838.55\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!ffmpeg -framerate 30 -i './datasets/data_out_post/leftEye/leftEyePost%d.jpg' -c:v libx264 -pix_fmt yuv420p -vf \"fps=30\" left_eye.mp4\n",
    "!ffmpeg -framerate 30 -i './datasets/data_out_post/rightEye/rightEyePost%d.jpg' -c:v libx264 -pix_fmt yuv420p -vf \"fps=30\" right_eye.mp4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1971f9",
   "metadata": {},
   "source": [
    "\n",
    "## Merge Videos and Inject Metadata\n",
    "\n",
    "Combine the left and right eye videos into an SBS video and inject 3D metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2b2c7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 6.0 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.0.40.1)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.0_1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58.  2.100 / 58.  2.100\n",
      "  libavcodec     60.  3.100 / 60.  3.100\n",
      "  libavformat    60.  3.100 / 60.  3.100\n",
      "  libavdevice    60.  1.100 / 60.  1.100\n",
      "  libavfilter     9.  3.100 /  9.  3.100\n",
      "  libswscale      7.  1.100 /  7.  1.100\n",
      "  libswresample   4. 10.100 /  4. 10.100\n",
      "  libpostproc    57.  1.100 / 57.  1.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'left_eye.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf60.3.100\n",
      "  Duration: 00:00:03.57, start: 0.000000, bitrate: 1799 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt470bg/unknown/unknown, progressive), 1280x720 [SAR 1:1 DAR 16:9], 1794 kb/s, 30 fps, 30 tbr, 15360 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.3.100 libx264\n",
      "Input #1, mov,mp4,m4a,3gp,3g2,mj2, from 'right_eye.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf60.3.100\n",
      "  Duration: 00:00:03.57, start: 0.000000, bitrate: 1844 kb/s\n",
      "  Stream #1:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt470bg/unknown/unknown, progressive), 1280x720 [SAR 1:1 DAR 16:9], 1840 kb/s, 30 fps, 30 tbr, 15360 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.3.100 libx264\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> hstack\n",
      "  Stream #1:0 (h264) -> hstack\n",
      "  hstack:default -> Stream #0:0 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x12470f2e0] \u001b[0musing SAR=1/1\n",
      "\u001b[1;36m[libx264 @ 0x12470f2e0] \u001b[0musing cpu capabilities: ARMv8 NEON\n",
      "\u001b[1;36m[libx264 @ 0x12470f2e0] \u001b[0mprofile High, level 4.0, 4:2:0, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x12470f2e0] \u001b[0m264 - core 164 r3108 31e19f9 - H.264/MPEG-4 AVC codec - Copyleft 2003-2023 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=21 lookahead_threads=3 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'output.SBS.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf60.3.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 2560x720 [SAR 1:1 DAR 32:9], q=2-31, 30 fps, 15360 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc60.3.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=  107 fps=0.0 q=-1.0 Lsize=    1423kB time=00:00:03.46 bitrate=3363.4kbits/s speed=5.14x     \n",
      "video:1421kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.149249%\n",
      "\u001b[1;36m[libx264 @ 0x12470f2e0] \u001b[0mframe I:3     Avg QP:20.31  size: 69542\n",
      "\u001b[1;36m[libx264 @ 0x12470f2e0] \u001b[0mframe P:28    Avg QP:22.45  size: 22849\n",
      "\u001b[1;36m[libx264 @ 0x12470f2e0] \u001b[0mframe B:76    Avg QP:25.05  size:  7976\n",
      "\u001b[1;36m[libx264 @ 0x12470f2e0] \u001b[0mconsecutive B-frames:  4.7%  1.9%  0.0% 93.5%\n",
      "\u001b[1;36m[libx264 @ 0x12470f2e0] \u001b[0mmb I  I16..4: 14.0% 76.3%  9.7%\n",
      "\u001b[1;36m[libx264 @ 0x12470f2e0] \u001b[0mmb P  I16..4:  6.7% 12.8%  0.5%  P16..4: 44.4% 10.6%  2.8%  0.0%  0.0%    skip:22.3%\n",
      "\u001b[1;36m[libx264 @ 0x12470f2e0] \u001b[0mmb B  I16..4:  0.3%  0.5%  0.0%  B16..8: 41.0%  3.6%  0.4%  direct: 0.8%  skip:53.3%  L0:46.1% L1:52.0% BI: 1.9%\n",
      "\u001b[1;36m[libx264 @ 0x12470f2e0] \u001b[0m8x8 transform intra:67.8% inter:84.6%\n",
      "\u001b[1;36m[libx264 @ 0x12470f2e0] \u001b[0mcoded y,uvDC,uvAC intra: 38.9% 50.2% 5.6% inter: 7.7% 9.0% 0.0%\n",
      "\u001b[1;36m[libx264 @ 0x12470f2e0] \u001b[0mi16 v,h,dc,p: 16% 43% 10% 31%\n",
      "\u001b[1;36m[libx264 @ 0x12470f2e0] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 17% 28% 28%  3%  5%  5%  6%  3%  4%\n",
      "\u001b[1;36m[libx264 @ 0x12470f2e0] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 23% 25% 14%  4% 10%  9%  8%  4%  4%\n",
      "\u001b[1;36m[libx264 @ 0x12470f2e0] \u001b[0mi8c dc,h,v,p: 54% 28% 15%  3%\n",
      "\u001b[1;36m[libx264 @ 0x12470f2e0] \u001b[0mWeighted P-Frames: Y:3.6% UV:0.0%\n",
      "\u001b[1;36m[libx264 @ 0x12470f2e0] \u001b[0mref P L0: 69.0% 10.3% 16.0%  4.6%  0.2%\n",
      "\u001b[1;36m[libx264 @ 0x12470f2e0] \u001b[0mref B L0: 90.1%  8.5%  1.4%\n",
      "\u001b[1;36m[libx264 @ 0x12470f2e0] \u001b[0mref B L1: 95.5%  4.5%\n",
      "\u001b[1;36m[libx264 @ 0x12470f2e0] \u001b[0mkb/s:3262.64\n",
      "ffmpeg version 6.0 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.0.40.1)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.0_1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58.  2.100 / 58.  2.100\n",
      "  libavcodec     60.  3.100 / 60.  3.100\n",
      "  libavformat    60.  3.100 / 60.  3.100\n",
      "  libavdevice    60.  1.100 / 60.  1.100\n",
      "  libavfilter     9.  3.100 /  9.  3.100\n",
      "  libswscale      7.  1.100 /  7.  1.100\n",
      "  libswresample   4. 10.100 /  4. 10.100\n",
      "  libpostproc    57.  1.100 / 57.  1.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'output.SBS.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf60.3.100\n",
      "  Duration: 00:00:03.57, start: 0.000000, bitrate: 3269 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(progressive), 2560x720 [SAR 1:1 DAR 32:9], 3264 kb/s, 30 fps, 30 tbr, 15360 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.3.100 libx264\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x14b106320] \u001b[0musing SAR=9/32\n",
      "\u001b[1;36m[libx264 @ 0x14b106320] \u001b[0musing cpu capabilities: ARMv8 NEON\n",
      "\u001b[1;36m[libx264 @ 0x14b106320] \u001b[0mprofile High, level 5.0, 4:2:0, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x14b106320] \u001b[0m264 - core 164 r3108 31e19f9 - H.264/MPEG-4 AVC codec - Copyleft 2003-2023 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=21 lookahead_threads=3 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 frame-packing=3 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'output_final_sbs.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf60.3.100\n",
      "  Stream #0:0(und): Video: h264 (avc1 / 0x31637661), yuv420p(tv, progressive), 5120x720 [SAR 9:32 DAR 2:1], q=2-31, 30 fps, 15360 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.3.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame=  107 fps= 85 q=-1.0 Lsize=    2218kB time=00:00:03.46 bitrate=5240.9kbits/s speed=2.76x     \n",
      "video:2216kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.096701%\n",
      "\u001b[1;36m[libx264 @ 0x14b106320] \u001b[0mframe I:3     Avg QP:20.01  size: 95943\n",
      "\u001b[1;36m[libx264 @ 0x14b106320] \u001b[0mframe P:29    Avg QP:22.13  size: 35473\n",
      "\u001b[1;36m[libx264 @ 0x14b106320] \u001b[0mframe B:75    Avg QP:24.16  size: 12688\n",
      "\u001b[1;36m[libx264 @ 0x14b106320] \u001b[0mconsecutive B-frames:  4.7%  5.6%  0.0% 89.7%\n",
      "\u001b[1;36m[libx264 @ 0x14b106320] \u001b[0mmb I  I16..4: 20.7% 73.0%  6.2%\n",
      "\u001b[1;36m[libx264 @ 0x14b106320] \u001b[0mmb P  I16..4:  9.7% 13.2%  0.3%  P16..4: 44.0%  7.1%  1.0%  0.0%  0.0%    skip:24.7%\n",
      "\u001b[1;36m[libx264 @ 0x14b106320] \u001b[0mmb B  I16..4:  0.5%  0.5%  0.0%  B16..8: 37.4%  2.3%  0.1%  direct: 0.8%  skip:58.3%  L0:45.3% L1:52.6% BI: 2.1%\n",
      "\u001b[1;36m[libx264 @ 0x14b106320] \u001b[0m8x8 transform intra:61.1% inter:90.3%\n",
      "\u001b[1;36m[libx264 @ 0x14b106320] \u001b[0mcoded y,uvDC,uvAC intra: 28.3% 40.1% 2.0% inter: 5.5% 8.9% 0.0%\n",
      "\u001b[1;36m[libx264 @ 0x14b106320] \u001b[0mi16 v,h,dc,p: 15% 56% 10% 19%\n",
      "\u001b[1;36m[libx264 @ 0x14b106320] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 11% 45% 27%  2%  3%  1%  7%  1%  3%\n",
      "\u001b[1;36m[libx264 @ 0x14b106320] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 14% 49% 14%  2%  6%  2%  9%  1%  3%\n",
      "\u001b[1;36m[libx264 @ 0x14b106320] \u001b[0mi8c dc,h,v,p: 47% 40% 10%  2%\n",
      "\u001b[1;36m[libx264 @ 0x14b106320] \u001b[0mWeighted P-Frames: Y:3.4% UV:0.0%\n",
      "\u001b[1;36m[libx264 @ 0x14b106320] \u001b[0mref P L0: 68.2%  9.4% 17.0%  5.3%  0.2%\n",
      "\u001b[1;36m[libx264 @ 0x14b106320] \u001b[0mref B L0: 89.5%  9.0%  1.5%\n",
      "\u001b[1;36m[libx264 @ 0x14b106320] \u001b[0mref B L1: 95.3%  4.7%\n",
      "\u001b[1;36m[libx264 @ 0x14b106320] \u001b[0mkb/s:5087.42\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!ffmpeg -i left_eye.mp4 -i right_eye.mp4 -filter_complex \"[0:v][1:v]hstack=inputs=2[v]\" -map \"[v]\" output.SBS.mp4\n",
    "!ffmpeg -i output.SBS.mp4 -vf \"scale=2*iw:ih\" -c:v libx264 -x264opts \"frame-packing=3\" -aspect 2:1 output_final_sbs.mp4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f75dc8",
   "metadata": {},
   "source": [
    "\n",
    "## Cleanup and Finalization\n",
    "\n",
    "(Optional) Cleanup temporary files and display/export the final video path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38160454",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example cleanup (adjust as needed)\n",
    "# !rm -rf video_images/\n",
    "# !rm left_eye.mp4 right_eye.mp4\n",
    "\n",
    "# Display the final video path\n",
    "final_video_path = 'outputv2-3D.mp4'\n",
    "final_video_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
