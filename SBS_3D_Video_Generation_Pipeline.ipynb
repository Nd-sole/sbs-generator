{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cee2917f",
   "metadata": {},
   "source": [
    "\n",
    "# SBS 3D Video Generation Pipeline\n",
    "\n",
    "This notebook outlines the process of converting a monocular video into a side-by-side (SBS) 3D video.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e231e45a",
   "metadata": {},
   "source": [
    "\n",
    "## Setup and Preparation\n",
    "\n",
    "Import necessary libraries and define the input video path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca7e718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Define the path to the input video\n",
    "input_video_path = 'datasets/data_in/input.mp4'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caf08b7",
   "metadata": {},
   "source": [
    "\n",
    "## Extract Frames from Video\n",
    "\n",
    "Use ffmpeg to extract frames from the input video.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d488a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!ffmpeg -i {input_video_path} -q:v 2 datasets/data_in/frame%d.jpg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321b274d",
   "metadata": {},
   "source": [
    "\n",
    "## Generate Depth Images\n",
    "\n",
    "In this step, we generate depth maps for each color frame. We are using a cross-platform library called [Marigold](https://github.com/prs-eth/Marigold?tab=readme-ov-file), which works well on both Mac and Windows. Marigold is designed to efficiently generate depth maps and is particularly optimized for Apple Silicon.\n",
    "\n",
    "For Windows users, an alternative tool called [PatchFusion](https://zhyever.github.io/patchfusion/) is recommended. It's important to note that any depth map model compatible with your operating system can be used in this step. The key requirement is to obtain a depth map for each color frame.\n",
    "\n",
    "**Ensure that your datasets are placed in the specified input directory, and the output directory is set up to receive the depth maps.**\n",
    "\n",
    "# Running Marigold on Mac\n",
    "\n",
    "To generate depth maps using Marigold on a Mac, especially optimized for Apple Silicon, run the following command in the directory containing the Marigold library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e88ff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run.py --input_rgb_dir datasets/d0/data_in/ --output_dir datasets/d0/data_out/ --apple_silicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb9eaab",
   "metadata": {},
   "source": [
    "\n",
    "## Image Preprocessing\n",
    "\n",
    "Rename and pair images as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d702eabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for renaming images (adjust according to your script)\n",
    "!python sbs_rename_directory.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f53677d",
   "metadata": {},
   "source": [
    "For color, run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15957937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "source_dir = \"./datasets/d2/battle/battle_in/\"\n",
    "target_prefix = \"color\"\n",
    "\n",
    "def get_frame_number(filename):\n",
    "    return int(filename.split(\"frame\")[1].split(\".\")[0])\n",
    "\n",
    "\n",
    "file_list = os.listdir(source_dir)\n",
    "frame_files = sorted([f for f in file_list if f.startswith(\"frame\") and f.endswith(\".jpg\")], key=get_frame_number)\n",
    "counter = 0\n",
    "\n",
    "for filename in frame_files:\n",
    "    new_name = f\"{target_prefix}{counter}.jpg\"\n",
    "    os.rename(os.path.join(source_dir, filename), os.path.join(source_dir, new_name))\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d276b6cc",
   "metadata": {},
   "source": [
    "For depth, run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51cfe450",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_frame_number\u001b[39m(filename):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(filename\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m----> 8\u001b[0m file_list \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(source_dir)\n\u001b[1;32m      9\u001b[0m frame_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m([f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m file_list \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)], key\u001b[38;5;241m=\u001b[39mget_frame_number)\n\u001b[1;32m     10\u001b[0m counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "source_dir = \"./datasets/d2/battle/battle_in/\"\n",
    "target_prefix = \"depth\"\n",
    "\n",
    "def get_frame_number(filename):\n",
    "    return int(filename.split(\"frame\")[1].split(\".\")[0])\n",
    "\n",
    "\n",
    "file_list = os.listdir(source_dir)\n",
    "frame_files = sorted([f for f in file_list if f.startswith(\"frame\") and f.endswith(\".png\")], key=get_frame_number)\n",
    "counter = 0\n",
    "\n",
    "for filename in frame_files:\n",
    "    new_name = f\"{target_prefix}{counter}.png\"\n",
    "    os.rename(os.path.join(source_dir, filename), os.path.join(source_dir, new_name))\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca376732",
   "metadata": {},
   "source": [
    "\n",
    "## Generate Stereo Views\n",
    "\n",
    "Run the script to generate left and right eye views.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d21ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python sbs_generate_stereoviews.py datasets/d2/data_in/ datasets/d2/data_out/  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0e0726",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def process_images(input_dir, output_dir, scale_factor):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    color_images = sorted([f for f in os.listdir(input_dir) if f.startswith('color')])\n",
    "    depth_images = sorted([f for f in os.listdir(input_dir) if f.startswith('depth')])\n",
    "\n",
    "    for color_image_path, depth_image_path in zip(color_images, depth_images):\n",
    "        color_image = cv2.imread(os.path.join(input_dir, color_image_path))\n",
    "        depth_map = cv2.imread(os.path.join(input_dir, depth_image_path), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if color_image is None:\n",
    "            print(f\"Error: Color image not found at {os.path.join(input_dir, color_image_path)}\")\n",
    "            continue\n",
    "\n",
    "        if depth_map is None:\n",
    "            print(f\"Error: Depth map not found at {os.path.join(input_dir, depth_image_path)}\")\n",
    "            continue\n",
    "\n",
    "        # Function to shift pixels based on depth map\n",
    "        def shift_pixels(image, depth_map, direction):\n",
    "            shifted_image = np.zeros_like(image)\n",
    "            for y in range(image.shape[0]):\n",
    "                for x in range(image.shape[1]):\n",
    "                    disparity = calculate_disparity(depth_map[y, x])\n",
    "                    new_x = x + disparity * direction\n",
    "                    if 0 <= new_x < image.shape[1]:\n",
    "                        shifted_image[y, new_x] = image[y, x]\n",
    "            return shifted_image\n",
    "\n",
    "        # Calculate disparity (example function, adjust as needed)\n",
    "        def calculate_disparity(depth_value):\n",
    "            # Simple linear mapping, adjust the scale factor as needed\n",
    "            return int(depth_value * scale_factor)\n",
    "\n",
    "        # Create left and right eye images\n",
    "        left_eye_image = shift_pixels(color_image, depth_map, 1)\n",
    "        right_eye_image = shift_pixels(color_image, depth_map, -1)\n",
    "\n",
    "        frame_number = color_image_path.split('color')[1].split('.')[0]\n",
    "        \n",
    "        if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "        left_eye_output_path = os.path.join(output_dir, f'leftEye/leftEye{frame_number}.jpg')\n",
    "        right_eye_output_path = os.path.join(output_dir, f'rightEye/rightEye{frame_number}.jpg')\n",
    "\n",
    "        # Save the left and right eye images\n",
    "        cv2.imwrite(left_eye_output_path, left_eye_image)\n",
    "        cv2.imwrite(right_eye_output_path, right_eye_image)\n",
    "\n",
    "        print(f\"Processed frame {frame_number}.\")\n",
    "\n",
    "# Example usage\n",
    "process_images('./datasets/d2/data_in/', './datasets/d2/data_out/', 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a55b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def shift_pixels(image, depth_map, direction, scale_factor):\n",
    "    shifted_image = np.zeros_like(image)\n",
    "    for y in range(image.shape[0]):\n",
    "        for x in range(image.shape[1]):\n",
    "            disparity = int(depth_map[y, x] * scale_factor)\n",
    "            new_x = x + disparity * direction\n",
    "            if 0 <= new_x < image.shape[1]:\n",
    "                shifted_image[y, new_x] = image[y, x]\n",
    "    return shifted_image\n",
    "\n",
    "def process_single_image_pair(color_image_path, depth_image_path, input_dir, output_dir, scale_factor):\n",
    "    try:\n",
    "        color_image = cv2.imread(os.path.join(input_dir, color_image_path))\n",
    "        depth_map = cv2.imread(os.path.join(input_dir, depth_image_path), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if color_image is None or depth_map is None:\n",
    "            return f\"Error: Image not found at {os.path.join(input_dir, color_image_path)} or {os.path.join(input_dir, depth_image_path)}\"\n",
    "\n",
    "        left_eye_image = shift_pixels(color_image, depth_map, 1, scale_factor)\n",
    "        right_eye_image = shift_pixels(color_image, depth_map, -1, scale_factor)\n",
    "\n",
    "        frame_number = color_image_path.split('color')[1].split('.')[0]\n",
    "        left_eye_output_path = os.path.join(output_dir, f'leftEye{frame_number}.jpg')\n",
    "        right_eye_output_path = os.path.join(output_dir, f'rightEye{frame_number}.jpg')\n",
    "\n",
    "        cv2.imwrite(left_eye_output_path, left_eye_image)\n",
    "        cv2.imwrite(right_eye_output_path, right_eye_image)\n",
    "\n",
    "        return f\"Processed frame {frame_number}.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error processing {color_image_path}: {e}\"\n",
    "\n",
    "def process_images(input_dir, output_dir, scale_factor):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    color_images = sorted([f for f in os.listdir(input_dir) if f.startswith('color')])\n",
    "    depth_images = sorted([f for f in os.listdir(input_dir) if f.startswith('depth')])\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        futures = [executor.submit(process_single_image_pair, color_image_path, depth_image_path, input_dir, output_dir, scale_factor) for color_image_path, depth_image_path in zip(color_images, depth_images)]\n",
    "\n",
    "    for future in as_completed(futures):\n",
    "        print(future.result())\n",
    "\n",
    "# Example usage\n",
    "process_images('./datasets/data_in/', './datasets/data_out_fast/', 0.05)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35adf01f",
   "metadata": {},
   "source": [
    "\n",
    "## Inpainting Process\n",
    "\n",
    "Run the script for inpainting left and right eye images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8cb281",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python sbs_inpaint_stereoviews.py data_out/ data_out_final/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56acc662",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def create_mask_for_black_streaks(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Use adaptive thresholding to better capture the black streaks\n",
    "    mask = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 3, 8)\n",
    "    \n",
    "    # Dilate the mask to include the edges of the black streaks\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def inpaint_black_streaks(image, mask):\n",
    "    # Inpaint the black streaks in the image\n",
    "    inpainted_image = cv2.inpaint(image, mask, 5, cv2.INPAINT_TELEA)\n",
    "    \n",
    "    return inpainted_image\n",
    "\n",
    "def process_images(input_dir, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    left_path = input_dir + \"leftEye/\"\n",
    "    right_path = input_dir + \"rightEye/\"\n",
    "    left_eye_images = sorted([f for f in os.listdir(left_path) if f.startswith('leftEye')])\n",
    "    right_eye_images = sorted([f for f in os.listdir(right_path) if f.startswith('rightEye')])\n",
    "\n",
    "    for left_eye_image_path, right_eye_image_path in zip(left_eye_images, right_eye_images):\n",
    "        left_eye_image = cv2.imread(os.path.join(left_path, left_eye_image_path))\n",
    "        right_eye_image = cv2.imread(os.path.join(right_path, right_eye_image_path))\n",
    "\n",
    "        if left_eye_image is None or right_eye_image is None:\n",
    "            print(f\"Error: Image not found at {os.path.join(input_dir, left_eye_image_path)} or {os.path.join(input_dir, right_eye_image_path)}\")\n",
    "            continue\n",
    "\n",
    "        # Create masks for the black streaks in both left and right eye images\n",
    "        left_eye_mask = create_mask_for_black_streaks(left_eye_image)\n",
    "        right_eye_mask = create_mask_for_black_streaks(right_eye_image)\n",
    "\n",
    "        # Inpaint the black streaks in both left and right eye images\n",
    "        left_eye_post = inpaint_black_streaks(left_eye_image, left_eye_mask)\n",
    "        right_eye_post = inpaint_black_streaks(right_eye_image, right_eye_mask)\n",
    "\n",
    "        frame_number = left_eye_image_path.split('leftEye')[1].split('.')[0]\n",
    "        left_eye_post_output_path = os.path.join(output_dir + \"leftEye/\", f'leftEyePost{frame_number}.jpg')\n",
    "        right_eye_post_output_path = os.path.join(output_dir + \"rightEye/\", f'rightEyePost{frame_number}.jpg')\n",
    "\n",
    "        # Save the processed images and masks\n",
    "        cv2.imwrite(left_eye_post_output_path, left_eye_post)\n",
    "        cv2.imwrite(right_eye_post_output_path, right_eye_post)\n",
    "\n",
    "        print(f\"Processed frame {frame_number}.\")\n",
    "\n",
    "# Example usage\n",
    "process_images('./datasets/d2/data_out/', './datasets/d2/data_out_post/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adc9976",
   "metadata": {},
   "source": [
    "\n",
    "## Create Videos from Images\n",
    "\n",
    "Use ffmpeg to create left and right eye videos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83851e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!ffmpeg -framerate 24 -i './datasets/d2/data_out_post/leftEye/leftEyePost%d.jpg' -c:v libx264 -pix_fmt yuv420p -vf \"fps=24\" left_eye.mp4\n",
    "!ffmpeg -framerate 24 -i './datasets/d2/data_out_post/rightEye/rightEyePost%d.jpg' -c:v libx264 -pix_fmt yuv420p -vf \"fps=24\" right_eye.mp4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1971f9",
   "metadata": {},
   "source": [
    "\n",
    "## Merge Videos and Inject Metadata\n",
    "\n",
    "Combine the left and right eye videos into an SBS video and inject 3D metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b2c7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!ffmpeg -i left_eye.mp4 -i right_eye.mp4 -filter_complex \"[0:v][1:v]hstack=inputs=2[v]\" -map \"[v]\" datasets\\d2\\output.SBS.mp4\n",
    "!ffmpeg -i datasets\\d2\\output.SBS.mp4 -vf \"scale=2*iw:ih\" -c:v libx264 -x264opts \"frame-packing=3\" -aspect 2:1 datasets\\d2\\output_final_sbs.mp4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f75dc8",
   "metadata": {},
   "source": [
    "\n",
    "## Cleanup and Finalization\n",
    "\n",
    "(Optional) Cleanup temporary files and display/export the final video path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38160454",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example cleanup (adjust as needed)\n",
    "# !rm -rf video_images/\n",
    "# !rm left_eye.mp4 right_eye.mp4\n",
    "\n",
    "# Display the final video path\n",
    "final_video_path = 'outputv2-3D.mp4'\n",
    "final_video_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
